<?xml version="1.0" encoding="UTF-8"?>
<bank>
  <topic>PCA03 - Brain Dump</topic>
  <!-- STRUCTURE DEFINITION:
  <entry>
    <question>XXX</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>XXX</detail>
        </option>
      </options>
    </answer>
  </entry> 
  -->
  <entry>
    <question>You have application data that you need to access on a monthly basis, with the requirement that data older than five years is no longer necessary. What steps can you take to minimize storage expenses? Select all that apply.</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>You should store infrequently accessed data in a Nearline storage class.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should store infrequently accessed data in a multi-regional bucket.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should set an object lifecycle management policy to change the storage class to Archive for data older than 5 years.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should store infrequently accessed data in a Standard storage class.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should set an object lifecycle management policy to remove data older than 5 years.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your organization operates a multi-tier web application on Google Cloud. You have been tasked with implementing a solution to ensure operational reliability and quickly identify any issues that might affect the application's performance. Which of the following would be the best approach?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Enable Cloud Logging and Monitoring for the entire project.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Dataflow to process logs in real-time.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Configure Cloud Pub/Sub to publish messages whenever there is a change in the application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Enable Cloud Debugger on all application instances.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A web application uses Cloud SQL to store user data which is very critical for the application flow. As a cloud architect, you want to protect your data from zone failures. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should create a Read replica in the same region but in a different zone.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should create a Read replica in a different region.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You cannot increase availability of your application in this case.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should configure High Availability for Cloud SQL.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a cloud architect working for a fintech company that wants to deploy a critical, containerized application in a microservices architecture. The application needs to support high levels of incoming traffic with low latency, ensure zero-downtime deployments, allow for automatic scaling based on CPU utilization, and maintain end-to-end encryption. Which of the following deployment methods should you choose for this scenario?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Deploy the application on Compute Engine instances behind a load balancer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Deploy the application on App Engine Standard environment.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Deploy the application on Google Kubernetes Engine (GKE) with an HTTPS load balancer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Deploy the application on App Engine Flexible environment.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>In your company, each employee has a credit card assigned to their account. As a cloud architect, you want to consolidate the billing of all GCP projects into a new billing account. With Google best practices in mind, how should you do it?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should send an email to Google Billing Support and request them to create a new billing account and link all the projects to the billing account.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>In the GCP Console, move all projects to the root organization in the Resource Manager.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Once a credit card is assigned to the project, it cannot be changed. You have to create all the projects from scratch with new billing account.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should create a new Billing account and set up a payment method with company credit card.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your customer is planning to run a machine learning workload on Google Cloud. The customer has the following requirements:
- the workload must be able to scale dynamically to handle large amounts of data
- the workload must be able to process data in parallel
- the workload must be able to handle failures and recover gracefully
- the workload must be cost-effective
Which Google Cloud service should you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>TensorFlow</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud AutoML</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Cloud AI Platform</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Machine Learning Engine</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are responsible for preparing a migration plan for your company. You want to migrate Apache Kafka (real-time streaming data pipelines) to the Google Cloud. Which Google Cloud service should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Cloud Datastore</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Bigtable</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Firestore</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Cloud Pub/Sub</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A financial services company is planning to implement a high-performance computing solution on GCP to support its algorithmic trading operations. The company wants to ensure that the solution is scalable, low-latency, and able to handle a large volume of data. The company also wants to ensure that the solution is secure and that sensitive financial data is protected. Which of the following options would be the most effective approach to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Functions to stream the data and Cloud Dataflow to process the data. Use BigQuery to store the data and Cloud IAM to control access to the data. Implement security using Cloud KMS.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Pub/Sub to stream the data and Cloud Dataproc to process the data. Use BigQuery to store the data and Cloud IAM to control access to the data. Implement security using Cloud IAP.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Gogle Cloud Pub/Sub to stream the data and Cloud Dataflow to process the data. Use Cloud Bigtable to store the data and Cloud IAM to control access to the data. Implement security using Cloud KMS.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Pub/Sub to stream the data and Cloud Dataproc to process the data. Use Cloud Bigtable to store the data and Cloud IAM to control access to the data. Implement security using Cloud IAP.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A large media company wants to implement a system for processing user-generated content, such as images and videos, and automatically categorize them based on visual content. The system should be able to process large amounts of data in real-time and scale as needed. The company wants to use the Google Cloud Platform for this implementation. Which of the following options would be the best solution for this requirement?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Pub/Sub to ingest the user-generated content, BigQuery to store the data, and Vertex AI to categorize the content.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Cloud Storage to store the user-generated content, Cloud Dataproc to process the data, and Vertex AI to categorize the content.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Storage to store the user-generated content, Cloud Functions to process the data and categorize the content.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Storage to store the user-generated content, Cloud Dataflow to process the data and categorize the content.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are tasked with creating a signed URL for a Google Cloud Storage (GCS) bucket. The requirement is to allow access to a certain object in the bucket for a third-party service, but only for 30 minutes. The solution should ensure minimum privileges and security. Which of the following options should you choose to implement this?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Create a signed URL using a user-managed service account with read access on the bucket and a 30-minute expiration.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Create a signed URL using a user-managed service account with full access on the bucket and a 30-minute expiration.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Create a signed URL using the bucket's default service account with a 30-minute expiration.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Create a signed URL using the bucket's default service account with no expiration, and manually invalidate the URL after 30 minutes.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are operating in a high-security environment where Compute Engine VMs are not permitted to access the public internet. Currently, you lack a VPN connection to access a local network file server. You have a necessity to deploy a certain software on a Compute Engine instance. What is the recommended method for installing the software?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Upload the necessary installation files to Cloud Source Repositories, and establish firewall rules to block all traffic except the IP address range for Cloud Source Repositories. Use gsutil to download the files to the VM.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Upload the necessary installation files to Cloud Storage. Configure the VM on a subnet with Private Google Access. Ensure the VM is assigned only an internal IP address. Use gsutil to download the installation files to the VM.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Upload the necessary installation files to Cloud Storage, and implement firewall rules to block all traffic except the IP address range specific to Cloud Storage. Utilize gsutil to download the files to the VM.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Upload the necessary installation files to Cloud Source Repositories. Set up the VM on a subnet with Private Google Access. Assign only an internal IP address to the VM. Use gcloud to download the installation files to the VM.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A mobile gaming company decided to migrate its analytics to BigQuery. Their analytics team needs access to perform queries against the data in BigQuery to improve user acquisition expenses for marketing campaigns. This analytics team members may change frequently. With Google best practices in mind, how do you grant access?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>You should create a Cloud Identity account for each analyst and add them all to a group. Then, grant BigQuery Data Viewer role to this group.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should create a Cloud Identity account for each analyst and add them all to a group. Then, grant BigQuery Data Owner role to this group.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should create a Cloud Identity account for each analyst. Then, grant BigQuery Data Owner role to each account.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should create a Cloud Identity account for each analyst. Then, grant BigQuery Data Viewer role to each account.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are migrating an application to GCP using overnight batch jobs that take approximately one hour. Which service should you recommend to do this with minimal cost?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should run the batch jobs in a GKE cluster.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should run the batch jobs in a preemptible compute engine instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should run the batch jobs in a virtual machine instance with GPUs.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should run the batch jobs in a normal virtual machine instance.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are tasked with designing a solution for a social media application that stores user-uploaded images in a Cloud Storage bucket. For each uploaded image, a thumbnail version needs to be generated for displaying in the application. The solution should be highly scalable to handle sudden spikes in uploads, cost-effective, and able to process images as soon as they are uploaded. What architecture would you suggest for this?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Compute Engine with a startup script to generate thumbnails.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Cloud Functions triggered by Cloud Storage events to generate thumbnails.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use App Engine to constantly check for new images and generate thumbnails.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Kubernetes Engine to constantly check for new images and generate thumbnails.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company has several applications running on GCP and on-premises. You need to create a hybrid cloud strategy to allow applications running on GCP to access data from your on-premises data center with low latency. What is the best strategy?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud VPN to create an IPsec VPN tunnel from the on-premises network to your VPC network on Google Cloud.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use VPC Network Peering to connect the on-premises network to your VPC network on Google Cloud.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Cloud Interconnect to create a dedicated connection from your on-premises network to your VPC network on Google Cloud.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Storage to store a copy of your on-premises data and access it from your applications on GCP.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>In your role as a cloud architect, you are using Cloud Shell and have the requirement to install a custom utility that will be utilized at a later stage. Where can you place the file to ensure it is in the default execution path and remains persistent across multiple sessions?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>~/bin</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>/usr/local/bin</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>In a Cloud Storage bucket</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>/google/scripts/bin</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A multinational retail company has stores in multiple countries and wants to leverage GCP to manage its inventory and ordering processes. The company wants to implement a mobile application that provides real-time visibility into inventory levels and enables employees to place orders for out-of-stock items from any location. The solution should also be scalable and be able to handle high volume transactions. Which of the following options would be the most effective approach to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud BigQuery to store the inventory data and Cloud Functions to trigger the ordering process. Use Cloud Pub/Sub to notify employees of inventory changes and Cloud IAM to control access to the data.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Cloud SQL to store the inventory data and App Engine to trigger the ordering process. Use Cloud Pub/Sub to notify employees of inventory changes and Cloud IAM to control access to the data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Storage to store the inventory data and Cloud Functions to trigger the ordering process. Use Cloud Pub/Sub to notify employees of inventory changes and Cloud IAM to control access to the data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Bigtable to store the inventory data and Cloud Dataflow to trigger the ordering process. Use Cloud Pub/Sub to notify employees of inventory changes and Cloud IAM to control access to the data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>The raw format of CCTV footage videos is stored by a machine learning startup in a Cloud Storage bucket. During the initial two-week period, the footage undergoes consistent processing to identify and detect potential threats. What storage approach would you suggest to minimize costs when storing the videos?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>You should use Standard storage class for the first two weeks, and use lifecycle rules to transition to Coldline.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should use Standard storage class for the first 30 days, and use lifecycle rules to transition to Coldline.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should use Standard storage class for the first two weeks, and then move videos to Persistent Disk.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should use Standard storage class for the first two weeks, and use lifecycle rules to transition to Nearline.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company is deploying a new application on GCP that requires global availability and has heavy content, such as video streaming. The application is designed to handle varying levels of traffic, and you expect users from around the world. What type of load balancer would be the best choice?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Internal HTTP(S) Load Balancer</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>HTTP(S) Load Balancer</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>SSL Proxy Load Balancer</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Network Load Balancer</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that needs to interact with Google Cloud Storage to store and retrieve data. You need to authenticate the application programmatically with GCP without user intervention. Which method would you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Cloud Identity</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>OAuth 2.0 Client ID</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Service Account</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Shell</detail>
        </option>
      </options>
    </answer>
  </entry> 
    <entry>
    <question>Your customer is planning to store and analyze large amounts of structured and unstructured data in Google Cloud. The customer has the following requirements:
- the data must be stored in a highly available and scalable storage system
- the data must be easily searchable and filterable
- the data must be easily queryable using SQL-like syntax
- the data must be easily integratable with other Google Cloud services
Which Google Cloud service should you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Cloud Bigtable</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Storage</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Cloud Firestore</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Datastore</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your organization operates a large-scale web application on Google Cloud, and you need to design a solution to analyze logs from the application in near real-time to detect any potential issues or anomalies. You also want to do some transformation of log data before storing. Which of the following approaches should you recommend?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Stream logs directly from the application to BigQuery.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Functions to process each log entry and send it to BigQuery.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Store logs in Cloud Storage, then use Cloud Dataflow to move them to BigQuery for analysis.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Cloud Pub/Sub to ingest logs, Cloud Dataflow to transform, and then BigQuery to analyze.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a cloud architect tasked with designing an application to regularly fetch and process social media data every 15 minutes. The processed data is then stored in Cloud Storage and made available to an analytics team. This operation must be reliable and scalable to handle periods of high demand, while minimizing costs. Which of the following is the most suitable approach to handle this scenario?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Compute Engine with a Cron job installed on the instance to fetch, process, and store the data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use App Engine Flexible with the Cron service to run a dedicated service for fetching and processing the data every 15 minutes.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use App Engine Standard with the Cron service to trigger a Cloud Run service every 15 minutes. The service retrieves and processes the data and then stores it in Cloud Storage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Scheduler to trigger a Pub/Sub topic every 15 minutes, which then triggers a Dataflow job to fetch, process, and store the data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>One of your applications is deployed to the GKE cluster as a Kubernetes workload with DaemonSets and is gaining popularity. As a cloud architect, you want to add more pods to your workload and want to make sure the cluster scales up and down automatically based on the volume. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>You should enable autoscaling on Kubernetes Engine.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should enable Horizontal Pod Autoscaling for the Kubernetes deployment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should create another identical Kubernetes workload and split traffic between the two workloads.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should perform a rolling update to modify machine type to a higher one.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are designing a cloud-based architecture for a company that requires a secure and scalable solution for its database. The database must be able to handle high volumes of transactions, and the data must be encrypted at rest and in transit. Which of the following options provides the best solution?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use a self-managed database service with manual encryption and scale-out capability.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use a NoSQL database service with built-in encryption and automatic scaling.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use a managed database service with automatic encryption and scale-up capability.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use a hybrid approach with a self-managed database service and a third-party encryption tool.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, it is your responsibility to monitor any modifications made to the Cloud Storage bucket. For each change, you are required to trigger an action that will promptly validate the compliance of the modification in near real-time. What action should you take?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should use Crone Scheduler to schedule your security script.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should use Cloud Function events, and call your security script from the Cloud Function triggers.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should use the built-in triggering mechanism of Cloud Storage to run your security script.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should use a Python script to get appropriate logs, analyze them, and run the security script.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your organization has an existing system on-premise and plans to migrate to Google Cloud. However, they plan to keep some parts of their system on-premises for the foreseeable future. The goal is to have the on-premise and cloud systems communicate securely and efficiently. What should be your strategy?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Use Cloud VPN to establish a secure connection between the on-premise system and Google Cloud</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Endpoints to create APIs for the on-premise system and access them from Google Cloud</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use VPC Network Peering to connect the on-premise system to the VPC in Google Cloud</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Interconnect to connect the on-premise system to Google Cloud</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you're working for a large e-commerce company that wants to detect anomalies in their sales data in real-time. The data is stored in BigQuery and is updated every few minutes with new sales information from around the globe. The goal is to quickly identify unusual spikes or drops in sales, so the business can take immediate actions. What would be the most efficient way to architect this solution?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Storage to store the sales data and periodically run batch processing jobs using Dataflow to detect anomalies.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Monitoring to monitor the sales data in BigQuery for anomalies.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud DLP (Data Loss Prevention) to monitor the sales data in BigQuery for anomalies.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use BigQuery ML to create a machine learning model and use scheduled queries to periodically perform anomaly detection on the recent data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Refer to the TerramEarth case study for this question: https://services.google.com/fh/files/blogs/master_case_study_terramearth.pdf
As TerramEarth increases its adoption of the Google Cloud Platform, which specific legacy enterprise processes within the company will undergo substantial modifications?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Capacity planning, utilization measurement, data center expansion</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Data center expansion, TCO calculations, utilization measurement</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>OPEX/CAPEX allocation, LAN change management, capacity planning</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Capacity planning, TCO calculations, OPEX/CAPEX allocation</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your customer is planning to run a big data analytics workload in Google Cloud. The customer has the following requirements:
- the workload must be able to handle a large volume of data and scale dynamically
- the workload must be able to process data in parallel
- the workload must be able to handle failures and recover gracefully
- the data must be easily queryable using SQL-like syntax
Which Google Cloud service should you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Cloud BigQuery</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Dataproc</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Dataflow</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud SQL</detail>
        </option>
      </options>
    </answer>
  </entry> 
    <entry>
    <question>As a cloud architect, you are working with a media company to develop a web application for live streaming events. The application needs to handle high incoming traffic during popular events. It's also important for the company to keep costs as low as possible when there are no live events (low traffic). Which environment of App Engine should you choose for this scenario?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>App Engine Standard environment, because it can scale to zero instances when there's no traffic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>App Engine Flexible environment, because it can scale to zero instances when there's no traffic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>App Engine Flexible environment, because it supports third-party software.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Both environments would suit this application equally well.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Refer to the EHR Healthcare case study for this question: https://services.google.com/fh/files/blogs/master_case_study_ehr_healthcare.pdf
The sales employees of EHR work remotely and travel to various locations for their job. These employees require access to web-based sales tools located in the EHR data center. EHR has made the decision to retire their existing Virtual Private Network (VPN) infrastructure, necessitating the migration of the web-based sales tools to a BeyondCorp access model. Each sales employee possesses a Google Workspace account, which they utilize for single sign-on (SSO) purposes. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should create a Google group for the sales tool application, and upgrade that group to a security group.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>For every sales employee who needs access to the sales tool application, you should give their Google Workspace user account the predefined AppEngine Viewer role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should deploy an external HTTP(S) load balancer and create a custom Cloud Armor policy for the sales tool application.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should create an Identity-Aware Proxy (IAP) connector that points to the sales tool application.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your organization provides a video streaming service to global users. Recently, users are complaining about the high latency when watching videos. As a cloud architect, how would you improve the streaming experience?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Use Cloud CDN to cache and serve video content.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Spanner to store and serve video content.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Store all video content in a single region in Cloud Storage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Pub/Sub to push video content to users.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, while utilizing the Google Network Intelligence Center's Firewall Insights feature, you observe that there are no log rows available for viewing when accessing the Firewall Insights page in the Google Cloud console. This prompts the need for assessing the effectiveness of the applied firewall ruleset, considering the existence of multiple firewall rules associated with the Compute Engine instance. To troubleshoot the issue, what steps should you take?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Enable Virtual Private Cloud (VPC) flow logging.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Install the Google Cloud SDK, and verify that there are no Firewall logs in the command line output.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Enable Firewall Rules Logging for the firewall rules you want to monitor.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Verify that your user account is assigned the compute.networkAdmin Identity and Access Management (IAM) role.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A large financial services company needs to build a secure and scalable platform for processing financial transactions. The platform must meet the following requirements:
- provide fast and secure transaction processing
- ensure data privacy and security
- enable real-time reporting and auditing
- minimize downtime during maintenance and upgrades
- minimize costs while still providing high performance
Which solution would you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Implementing a managed solution using Cloud Spanner for data storage and processing, Cloud Dataflow for real-time analytics, and Cloud Key Management Service (KMS) for secure payment processing.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a hybrid solution using Cloud SQL for data storage, Compute Engine for transaction processing, and BigQuery for real-time analytics.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a serverless solution using Cloud Functions for transaction processing, Cloud Firestore for data storage, and Cloud Pub/Sub for real-time data processing.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a custom-built solution using Cloud Pub/Sub for real-time data processing, Bigtable for data storage, and Google Kubernetes Engine (GKE) for deployment and scaling.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your customer is planning to deploy a web application that requires high performance and low latency. The customer has the following requirements:
- the application must be easily deployable and manageable
- the application must be highly available and recover from failures automatically
- the application must be able to handle incoming traffic spikes and scale dynamically
- the application must be cost-effective
Which Google Cloud service should you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>App Engine</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Load Balancer</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Google Kubernetes Engine</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Functions</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company runs several critical applications on Google Cloud. There has been a significant increase in the number of user-reported incidents recently, indicating performance issues. As a cloud architect, how would you improve the monitoring to proactively identify and address performance issues?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Set up custom metrics in Cloud Monitoring for all critical applications and configure alerting based on those metrics.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Trace to trace all requests to the applications.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Debugger to debug the applications in real-time.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Profiler to continuously profile the applications.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your organization uses BigQuery extensively for data analysis and you are developing a new solution to automate some recurring tasks. As part of this solution, you need to create a new table in BigQuery and load data into it from a CSV file in Cloud Storage, all from a Compute Engine instance. What would be the correct approach?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Use the bq command-line tool to both create the table and load the data from Cloud Storage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use the gsutil command to create the table in BigQuery and then the bq command-line tool to load the data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use the bq command-line tool to create the table and then the gsutil cp command to copy the data from Cloud Storage to BigQuery.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use the gcloud command-line tool to create the table and load the data into BigQuery.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Refer to the Mountkirk Games case study for this question: https://services.google.com/fh/files/blogs/master_case_study_mountkirk_games.pdf
As your new game is currently in public beta on the Google Cloud platform, it is essential to establish significant service level objectives (SLOs) before its official release to the public. What steps should you take to accomplish this?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should define one SLO as 99.9% game server availability. Define the other SLO as less than 100-ms latency.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should define one SLO as service availability that is the same as Google Cloud's availability. Define the other SLO as 100-ms latency.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should define one SLO as 99% HTTP requests return the 2xx status code. Define the other SLO as 99% requests return within 100 ms.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should define one SLO as total uptime of the game server within a week. Define the other SLO as the mean response time of all HTTP requests that are less than 100 ms.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A large logistics company is looking to build a secure and scalable platform for tracking shipments and managing delivery schedules. The platform must meet the following requirements:
- support real-time tracking of shipments with high accuracy
- ensure secure storage and processing of sensitive shipment information
- enable efficient coordination of delivery schedules across multiple locations
- minimize downtime during maintenance and upgrades
- minimize costs while still providing high performance
Which solution would you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Implementing a custom-built solution using Cloud Pub/Sub for real-time data processing, Bigtable for data storage, and Google Kubernetes Engine (GKE) for deployment and scaling.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a hybrid solution using Cloud SQL for data storage, Compute Engine for data processing, and BigQuery for real-time analytics.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Implementing a managed solution using Google Maps Platform for real-time tracking, Cloud Datastore for data storage, and Cloud Identity and Access Management (IAM) for secure access control.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a serverless solution using Cloud Functions for data processing, Cloud Firestore for data storage, and Cloud Pub/Sub for real-time data processing.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a cloud architect and have been tasked with creating a data retention policy on a Google Cloud Storage (GCS) bucket that holds sensitive client information. This policy should ensure that objects older than 90 days are not accessible, even if they haven't been deleted. Also, to ensure business continuity, deleted objects should be restorable within 5 days. Which of the following methods would be the most suitable for implementing this policy?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Apply a 90-day lifecycle rule to archive objects and enable versioning with a 5-day lifecycle rule to delete previous versions of objects.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Apply a 90-day lifecycle rule to delete objects and a 5-day retention policy to retain deleted objects.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Apply a 90-day retention policy to the bucket and a 5-day lifecycle rule to delete older versions of objects.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Apply a 90-day lifecycle rule to delete objects, enable versioning, and use a 5-day lifecycle rule to delete previous versions of objects.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A multinational retail company has a large number of physical stores across multiple countries. The company wants to implement a centralized system to monitor the energy consumption of each store in real-time and generate reports to help optimize energy usage. The company wants to use the Google Cloud Platform for this implementation. Which of the following options would be the best solution for this requirement?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud IoT Edge to connect the energy meters in each store to the cloud, Cloud SQL to store energy consumption data, and Cloud Pub/Sub to process the data and generate reports.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Pub/Sub to connect the energy meters in each store to the cloud, Cloud Datastore to store energy consumption data, and Cloud Functions to process the data and generate reports.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Cloud IoT Core to connect the energy meters in each store to the cloud, BigQuery to store energy consumption data, and Cloud Dataflow to process the data and generate reports.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud IoT Edge to connect the energy meters in each store to the cloud, Cloud Firestore to store energy consumption data, and Cloud Tasks to process the data and generate reports.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You're a cloud architect and have been assigned a task to develop a model that will predict the type of product a customer is most likely to purchase next, based on their past purchases and behavior. The client has a massive amount of historic data available but lacks machine learning expertise. Furthermore, the solution needs to be able to constantly learn from new data. Which of the following would be the best approach for this situation?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Use AutoML Tables, retrain the model periodically with new data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use BigQuery ML, retrain the model manually with new data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use AutoML Vision, retrain the model periodically with new data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Machine Learning Engine with TensorFlow and retrain the model manually with new data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are working for a company that needs to perform a large-scale data processing task that is highly parallelizable and not time-sensitive. This operation should be completed within a reasonable time frame, but it doesn't require an immediate result. The cost of operation is a major consideration. The company has asked you for the most cost-effective solution that matches these requirements. What would be your recommendation?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Google Cloud Dataflow with non-preemptible Compute Engine machines.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Google Kubernetes Engine with preemptible Compute Engine machines.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Google Cloud Dataproc with preemptible Compute Engine machines.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Google Cloud Functions for the data processing task.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A large healthcare organization needs to build a secure and scalable platform for storing and processing sensitive patient data. The platform must meet the following requirements:
- ensure secure storage and processing of sensitive patient data
- enable fast and efficient data retrieval for medical professionals
- support real-time data analysis for clinical decision-making
- enable data sharing with authorized partners while ensuring data privacy and security
- minimize costs while still providing high performance
Which solution would you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Implementing a serverless solution using Cloud Functions for data processing, Cloud Firestore for data storage, and Cloud Pub/Sub for real-time data processing.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Implementing a managed solution using Cloud Healthcare API for data storage and processing, Cloud Dataflow for real-time analytics, and Cloud Identity Access Management (IAM) for secure data sharing.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a custom-built solution using Cloud Pub/Sub for real-time data processing, Bigtable for data storage, and Google Kubernetes Engine (GKE) for deployment and scaling.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Implementing a hybrid solution using Cloud SQL for data storage, Compute Engine for data processing, and BigQuery for real-time analytics.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your customer is planning to store and analyze a large amount of time-series data in Google Cloud. The customer has the following requirements:
- the data must be stored in a highly available and scalable storage system
- the data must be easily accessible for real-time analytics
- single-digit millisecond latency
Which Google Cloud service should you recommend to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Cloud Storage</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Firestore</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Cloud Bigtable</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud SQL</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>An application processes a significant number of transactions that exceed the capabilities of a single virtual machine. As a cloud architect, you want to spread transactions across multiple servers in real time and in the most cost-effective way. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should set up Cloud SQL with a memory cache for speed. On your multiple servers, poll for transactions that do not have the processed key, and mark them processed when done.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should send transactions to Cloud Bigtable, and poll for new transactions from the VMs.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should send transactions to BigQuery. On the virtual machines, poll for transactions that don't have the processed key, and mark them processed when done.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should send transactions to Pub/Sub and process them in virtual machines in a Managed Instance Group.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>When handling Personally Identifiable Information (PII) in Google Cloud Platform (GCP), which of the following statements regarding Customer-managed encryption keys (CMEK) is correct?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>CMEK is automatically enabled by default for all GCP services, providing enhanced encryption and protection for PII.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>CMEK is a feature exclusively available for Google-managed services and cannot be utilized for customer-owned resources.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>CMEK ensures compliance with data protection regulations, eliminating the need for customers to implement additional security measures.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>CMEK provides customers with full control and ownership of encryption keys, allowing them to manage the encryption of all types of data within GCP.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>The database administration team has asked you to help them improve the performance of a new database server running on Compute Engine. The database is used to import and normalize company performance statistics. It is built with MySQL running on Debian Linux. They have an n1-standard-8 VM with 80 GB of SSD zonal persistent disk which they can't restart until the next maintenance event. What should they change to get better performance from this system as soon as possible and in a cost-effective manner?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Dynamically resize the SSD persistent disk to 500 GB.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Increase the virtual machines memory to 64 GB.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Migrate their performance metrics warehouse to BigQuery.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Create a new virtual machine running PostgreSQL.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a cloud architect for a company that has a multi-tier application running on GCP. The application includes a load balancer, several web servers, and a back-end database. As part of your security strategy, you want to allow HTTP(S) traffic only from the load balancer to the web servers. Which of the following would be the best approach?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Create a firewall rule with a high priority (low numeric value) to deny all traffic, and a rule with a low priority (high numeric value) to allow traffic from the load balancer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Create a firewall rule with a low priority (high numeric value) to allow traffic from the load balancer, and a default rule to deny all other traffic.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Create a firewall rule with a high priority (low numeric value) to allow traffic from the load balancer, and a default rule to deny all other traffic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Create two firewall rules with the same priority, one to allow traffic from the load balancer, and one to deny all other traffic.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an application with static content that is deployed in US region. What can you do to bring your content closer to European users?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should move the server to Europe.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should distribute static content using Cloud CDN.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should distribute static content using Cloud VPN.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should scale up the size of the web server.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You need to migrate your legacy on-premises applications to Google Cloud that are written in C++ and you want to use the serverless approach. What GCP compute services should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should deploy this application using a Managed Instance Group.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should deploy the containerized version of the application in App Engine Flexible.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should deploy the containerized version of the application in Cloud Run.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should deploy the containerized version of the application in Google Kubernetes Engine.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your organization uses a BigQuery data warehouse for analytics. You expect the volume of data and the complexity of queries to increase significantly over the next year. What could be a strategy to ensure query performance remains high?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Split your data into multiple BigQuery datasets to balance the load.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Migrate data from BigQuery to Cloud Spanner for increased performance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Increase the amount of storage available to BigQuery.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use the BigQuery Reservation model to purchase dedicated query processing capacity.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are working on a complex scenario where you have to deploy a monitoring pod in a DaemonSet object across a GKE cluster for a client's application. You want the monitoring pod to be deployed on every node of the GKE cluster. Which approach will allow you to efficiently achieve this objective?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Deploy the monitoring pod individually on each node in the GKE cluster.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Deploy the monitoring pod using a DaemonSet across the nodes in the GKE cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Deploy the monitoring pod using a StatefulSet across the nodes in the GKE cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Deploy the monitoring pod as a ReplicaSet across the nodes in the GKE cluster.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>In your role as a cloud architect, your task involves deploying PHP App Engine Standard alongside Cloud SQL as the backend, with the goal of reducing the number of queries to the database. What actions should you take?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Set the memcache service level to dedicated. Create a key from the hash of the query, and return database values from memcache before issuing a query to Cloud SQL.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Set the memcache service level to shared. Create a cron task that runs every minute to save all expected queries to a key called cached_queries.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Set the memcache service level to dedicated. Create a cron task that runs every minute to populate the cache with keys containing query results.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Set the memcache service level to shared. Create a key called cached_queries, and return database values from the key before using a query to Cloud SQL.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A financial services company is looking to implement a new fraud detection system for their credit card transactions. The system should be able to detect fraud in real-time and provide alerts to security personnel. The company wants to leverage the Google Cloud Platform for this implementation. Which of the following options would be the best solution for this requirement?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Datastore to store transaction data and use Cloud Functions to process transactions in real-time and trigger fraud alerts.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use BigQuery to store transaction data and use Cloud Dataflow to process transactions in real-time and trigger fraud alerts.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Firestore to store transaction data and use Cloud Tasks to process transactions in real-time and trigger fraud alerts.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud SQL to store transaction data and use Cloud Pub/Sub to process transactions in real-time and trigger fraud alerts.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are responsible for preparing a migration strategy. You need to deploy a disaster recovery infrastructure with the same design and configuration as your production environment using Google Cloud. Which topology would you use?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Mirrored topology</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Gated egress topology</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Gated ingress topology</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Handover topology</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a cloud architect tasked with designing a system to store petabytes of NoSQL data for a large-scale, global e-commerce company. The system needs to support high-speed writes and reads, provide seamless scalability, and ensure near real-time consistency. The data will be heavily used for both transactional and analytical workloads. Which Google Cloud service should you choose to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Cloud Datastore</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>BigQuery</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Cloud Bigtable</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Spanner</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you are assisting a global organization in migrating its petabyte-scale on-premises data to Google Cloud. The organization has an extremely slow internet connection, strict compliance and security standards, and cannot tolerate any downtime during working hours. The migration should be completed as quickly as possible without interrupting business operations. Which of the following strategies would you recommend?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Use Cloud Dataflow to process and migrate data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use gsutil command-line tool to upload data to Cloud Storage.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Use Transfer Appliance to ship data to Google Cloud.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Storage Transfer Service for online transfer.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You plan to migrate your on-premises MySQL and PostgreSQL databases to the Google Cloud using Lift and Shift approach. Which Google Cloud service should you use?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Database Migration Service</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Storage Transfer Service</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>BigQuery Data Transfer Service</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Migrate for Anthos</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>As a cloud architect, you work for a company that wants to try out the cloud with low risk. They want to archive approximately 500 TB of their log data to the cloud and test the serverless analytics features available to them there, while also retaining that data as a long-term disaster recovery backup. Which two steps should they take?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Load logs into BigQuery.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Insert logs into Cloud Bigtable.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Import logs into Cloud Logging.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Upload log files into Cloud Storage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Load logs into Cloud SQL.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Suppose your company has two VPC networks and they want to communicate internally between these networks. So that traffic stays within Google's network and doesn't traverse the public internet. Which service should you advise?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Hybrid Connectivity</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud VPN</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud DNS</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>VPC Network Peering</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You're designing a high-traffic web application on Google Cloud. The application involves dynamic content that changes frequently, but some parts of the data remain the same across different user sessions. You need to improve the application's performance and user experience by reducing the load on your databases. Which strategy should you adopt?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Implement a global Cloud Load Balancer.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Implement Cloud MemoryStore with Redis as an in-memory data store.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Cloud CDN to cache dynamic content.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Utilize Cloud Storage to store and retrieve commonly accessed data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Every year, an audit takes place within your company, and it is necessary to grant external auditors access to the audit logs from the past five years. What should you do to minimize the cost and operational overhead? (select 3)</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Export audit logs to Cloud Filestore.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Grant external auditors the role of Storage Object Viewer on the logs storage bucket.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Export audit logs to Cloud Storage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Export audit logs to BigQuery.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Configure a lifecycle management policy on the logs bucket to delete objects older than 5 years.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Refer to the Mountkirk Games case study for this question: https://services.google.com/fh/files/blogs/master_case_study_mountkirk_games.pdf
Mountkirk Games aims to establish a continuous delivery pipeline for their architecture, which comprises numerous small services requiring quick updates and rollbacks. The following requirements are specified by Mountkirk Games:
- redundant deployment of services across multiple regions in the US and Europe.
- only the frontend services are accessible via the public internet
- allocation of a single frontend IP address for their entire service fleet
- deployment artifacts are immutable
Which product combination would be most suitable for their needs?
</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Cloud Functions, Cloud Pub/Sub, Cloud Deployment Manager</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Container Registry, Google Kubernetes Engine, Cloud Load Balancing</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Storage, App Engine, Cloud Load Balancing</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Storage, Cloud Dataflow, Compute Engine</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You're designing a CI/CD pipeline for an application hosted on GCP. As part of the pipeline, you need to programmatically deploy and manage several GCP resources. Which approach should you use?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Google Cloud SDK and REST APIs</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Shell</detail>s
        </option>
        <option>
          <valid>false</valid>
          <detail>Cloud Deployment Manager</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Google Cloud Console</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company has an existing monolithic application running on-premises and you've been tasked to migrate this application to Google Cloud Platform (GCP). The company wants to start taking advantage of microservices for scalability and maintainability. What strategy should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Refactor the monolithic application into microservices and deploy each one as a Cloud Function.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Refactor the monolithic application into microservices and deploy using GKE.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Migrate the application to Cloud Run without refactoring, then move individual services to GKE as they are broken out.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Migrate the monolithic application to App Engine Standard, then refactor for microservices.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>An e-commerce company has petabytes of customer behavior data stored in private data center. Due to storage limitations in private data center, this company decided to migrate this data to GCP. The data must be available for your analysts, who have strong SQL background. How should you store the data to meet these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>You should import data into Cloud Datastore.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>You should import data into BigQuery.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should import data into Cloud SQL.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>You should import flat files into Cloud Storage.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>A social media startup deployed their image-sharing application using App Engine in the us-west1 region. After a few months, they notice that most of their users are based in Brazil. They want to minimize latency for their users. As a cloud architect, what should you advise them?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>They should update the default region to southamerica-east1 in the App Engine.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>They should use a global CDN to cache their content closer to their users in Brazil.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>They should create a ticket to Google Support to change application deployment region in App Engine.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>They should move this application deployment to southamerica-east1 region and create a new GCP project. Then, they should create a new App Engine application in the new GCP project and set its region to southamerica-east1. Finally, they should remove the old App Engine application.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Suppose you run a small business and need to grant a role for your accountant to view billing reports and approve invoices. With Google's best practices in mind, which Billing IAM role should you grant to your accountant?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Billing Account User Project Creator</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Billing Account Administrator</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Billing Account Viewer</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Billing Account Creator</detail>
        </option>
      </options>
    </answer>
  </entry> 
</bank>