<?xml version="1.0" encoding="UTF-8"?>
<bank>
  <topic>PCA01 - Brain Dump</topic>
  <!-- STRUCTURE DEFINITION:
  <entry>
    <question>XXX</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>XXX</detail>
        </option>
      </options>
    </answer>
  </entry> 
  -->
  <entry>
    <question>Your team is writing a backend application to implement the business logic for an interactive voice response (IVR) system that will support a payroll application. The IVR system has the following technical characteristics:
- Each customer phone call is associated with a unique IVR session.
- The IVR system creates a separate persistent gRPC connection to the backend for each session.
- If the connection is interrupted, the IVR system establishes a new connection, causing a slight latency for that call.
You need to determine which compute environment should be used to deploy the backend application. Using current call data, you determine that:
- Call duration ranges from 1 to 30 minutes.
- Calls are typically made during business hours.
- There are significant spikes of calls around certain known dates (e.g., pay days), or when large payroll changes occur.
You want to minimize cost, effort, and operational overhead. Where should you deploy the backend application?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Compute Engine</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Google Kubernetes Engine cluster in Standard mode</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Cloud Functions</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Cloud Run</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are using Cloud Build to build a Docker image. You need to modify the build to execute unit and run integration tests. When there is a failure, you want the build history to clearly display the stage at which the build failed. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Add RUN commands in the Dockerfile to execute unit and integration tests.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a Cloud Build build config file with a single build step to compile unit and integration tests.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a Cloud Build build config file that will spawn a separate cloud build pipeline for unit and integration tests.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create a Cloud Build build config file with separate cloud builder steps to compile and execute unit and integration tests.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that will be launched on Compute Engine instances across multiple distinct projects, each corresponding to the environments in your software development process (development, QA, staging, and production).The instances in each project have the same application code but different configurations. During deployment, each instance should receive the application’s configuration based on the environment it serves. You want to minimize the number of steps to configure this flow.What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. When creating your instances, configure a startup script using the gcloud command to determine the project name, which indicates the correct environment.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. In each project, configure a metadata key named "environment" whose value corresponds to the environment it serves. Use your deployment tool to query the instance metadata and configure the application based on the environment value.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy your chosen deployment tool on an instance in each project. Use a deployment job to retrieve the appropriate configuration file from your version control system, and apply the configuration when deploying the application on each instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. During each instance launch, configure an instance custom-metadata key named "environment" whose value corresponds to the environment the instance serves. Use your deployment tool to query the instance metadata, and configure the application based on the environment value.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an application running on Google Kubernetes Engine (GKE). The application is currently using a logging library and is outputting to standard output. You need to export the logs to Cloud Logging, and you need the logs to include metadata about each request. You want to use the simplest method to accomplish this. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Change your application’s logging library to the Cloud Logging library, and configure your application to export logs to Cloud Logging.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Update your application to output logs in JSON format, and add the necessary metadata to the JSON.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Update your application to output logs in CSV format, and add the necessary metadata to the CSV.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Install the Fluent Bit agent on each of your GKE nodes, and have the agent export all logs from /var/log.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a developer at a financial institution. You use Cloud Shell to interact with Google Cloud services. User data is currently stored on an ephemeral disk; however, a recently passed regulation mandates that you can no longer store sensitive information on an ephemeral disk. You need to implement a new storage solution for your user data. You want to minimize code changes.Where should you store your user data?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Store user data on a Cloud Shell home disk, and log in at least every 120 days to prevent its deletion.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Store user data on a persistent disk in a Compute Engine instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Store user data in a Cloud Storage bucket.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Store user data in BigQuery tables.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that will allow users to read and post comments on news articles. You want to configure your application to store and display user-submitted comments using Firestore. How should you design the schema to support an unknown number of comments and articles?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Store each comment in a subcollection of the article.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Add each comment to an array property on the article.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Store each comment in a document, and add the comment's key to an array property on the article.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Store each comment in a document, and add the comment's key to an array property on the user profile.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are designing an application that uses a microservices architecture. You are planning to deploy the application in the cloud and on-premises. You want to make sure the application can scale up on demand and also use managed services as much as possible. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Deploy open source Istio in a multi-cluster deployment on multiple Google Kubernetes Engine (GKE) clusters managed by Anthos.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Create a GKE cluster in each environment with Anthos, and use Cloud Run for Anthos to deploy your application to each cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Install a GKE cluster in each environment with Anthos, and use Cloud Build to create a Deployment for your application in each cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a GKE cluster in the cloud and install open-source Kubernetes on-premises. Use an external load balancer service to distribute traffic across the two environments.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are planning to deploy your application in a Google Kubernetes Engine (GKE) cluster.
The application exposes an HTTP-based health check at /healthz. You want to use this health check endpoint to determine whether traffic should be routed to the pod by the load balancer.
Which code snippet should you include in your Pod configuration?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>```
livenessProbe:
    httpGet:
        path: /healthz
        port: 80
```
</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>```
readinessProbe:
    httpGet:
        path: /healthz
         port: 80
```</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>```
loadbalancerHealthCheck:
    httpGet:
        path: /healthz
        port: 80
```</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>```
healthCheck:
    httpGet:
        path: /healthz
        port: 80
```</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your API backend is running on multiple cloud providers. You want to generate reports for the network latency of your API. Which two steps should you take? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use Zipkin collector to gather data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Fluentd agent to gather data.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use Cloud Trace to generate reports.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use Cloud Debugger to generate reports.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Use Cloud Profiler to generate reports.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing a Java Web Server that needs to interact with Google Cloud services via the Google Cloud API on the user's behalf. Users should be able to authenticate to the Google Cloud API using their Google Cloud identities. Which workflow should you implement in your web application?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>1. When a user arrives at your application, prompt them for their Google username and password.
2. Store an SHA password hash in your application's database along with the user's username.
3. The application authenticates to the Google Cloud API using HTTPs requests with the user's username and password hash in the Authorization request header.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. When a user arrives at your application, prompt them for their Google username and password.
2. Forward the user's username and password in an HTTPS request to the Google Cloud authorization server, and request an access token.
3. The Google server validates the user's credentials and returns an access token to the application.
4. The application uses the access token to call the Google Cloud API.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. When a user arrives at your application, route them to a Google Cloud consent screen with a list of requested permissions that prompts the user to sign in with SSO to their Google Account.2. After the user signs in and provides consent, your application receives an authorization code from a Google server.3. The Google server returns the authorization code to the user, which is stored in the browser's cookies.4. The user authenticates to the Google Cloud API using the authorization code in the cookie.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>1. When a user arrives at your application, route them to a Google Cloud consent screen with a list of requested permissions that prompts the user to sign in with SSO to their Google Account.
2. After the user signs in and provides consent, your application receives an authorization code from a Google server.
3. The application requests a Google Server to exchange the authorization code with an access token.
4. The Google server responds with the access token that is used by the application to call the Google Cloud API.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You need to load-test a set of REST API endpoints that are deployed to Cloud Run. The API responds to HTTP POST requests. Your load tests must meet the following requirements:
- Load is initiated from multiple parallel threads;
- User traffic to the API originates from multiple source IP addresses;
- Load can be scaled up using additional test instances;
You want to follow Google-recommended best practices. How should you configure the load testing?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create an image that has cURL installed, and configure cURL to run a test plan. Deploy the image in a managed instance group, and run one instance of the image for each VM.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create an image that has cURL installed, and configure cURL to run a test plan. Deploy the image in an unmanaged instance group, and run one instance of the image for each VM.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Deploy a distributed load testing framework on a private Google Kubernetes Engine cluster. Deploy additional Pods as needed to initiate more traffic and support the number of concurrent users.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Download the container image of a distributed load testing framework on Cloud Shell. Sequentially start several instances of the container on Cloud Shell to increase the load on the API.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are designing a schema for a table that will be moved from MySQL to Cloud Bigtable. The MySQL table is as follows:
```
AccountActivity
(
    Account_id int,
    Event_timestamp datetime,
    Transaction_type string,
    Amount numeric(18, 4)
) primary key (Account_id, Event_timestamp)
```
How should you design a row key for Cloud Bigtable for this table?
</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Set Account_id as a key.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Set Account_id_Event_timestamp as a key.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Set Event_timestamp_Account_id as a key.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Set Event_timestamp as a key.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing a single-player mobile game backend that has unpredictable traffic patterns as users interact with the game throughout the day and night.
You want to optimize costs by ensuring that you have enough resources to handle requests, but minimize over-provisioning. You also want the system to handle traffic spikes efficiently.
Which compute platform should you use?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Cloud Run</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Compute Engine with managed instance groups</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Compute Engine with unmanaged instance groups</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Google Kubernetes Engine using cluster autoscaling</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an application written in Python running in production on Cloud Run. Your application needs to read/write data stored in a Cloud Storage bucket in the same project. You want to grant access to your application following the principle of least privilege.
What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Create a user-managed service account with a custom Identity and Access Management (IAM) role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a user-managed service account with the Storage Admin Identity and Access Management (IAM) role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a user-managed service account with the Project Editor Identity and Access Management (IAM) role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use the default service account linked to the Cloud Run revision in production.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are using Cloud Build build to promote a Docker image to Development, Test, and Production environments. You need to ensure that the same Docker image is deployed to each of these environments.How should you identify the Docker image in your build?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use the latest Docker image tag.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use a unique Docker image name.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use the digest of the Docker image.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use a semantic version of Docker image tag.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You deployed a new application to Google Kubernetes Engine and are experiencing some performance degradation. Your logs are being written to Cloud Logging, and you are using a Prometheus sidecar model for capturing metrics. You need to correlate the metrics and data from the logs to troubleshoot the performance issue and send real-time alerts while minimizing costs. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create custom metrics from the Cloud Logging logs, and use Prometheus to import the results using the Cloud Monitoring REST API.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Export the Cloud Logging logs and the Prometheus metrics to Cloud Bigtable. Run a query to join the results, and analyze in Google Data Studio.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Export the Cloud Logging logs and stream the Prometheus metrics to BigQuery. Run a recurring query to join the results, and send notifications using Cloud Tasks.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Export the Prometheus metrics and use Cloud Monitoring to view them as external metrics. Configure Cloud Monitoring to create log-based metrics from the logs, and correlate them with the Prometheus data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team is setting up a build pipeline for an application that will run in Google Kubernetes Engine (GKE). For security reasons, you only want images produced by the pipeline to be deployed to your GKE cluster.
Which combination of Google Cloud services should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Cloud Build, Cloud Storage, and Binary Authorization</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Google Cloud Deploy, Cloud Storage, and Google Cloud Armor</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Google Cloud Deploy, Artifact Registry, and Google Cloud Armor</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Cloud Build, Artifact Registry, and Binary Authorization</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application using different microservices that must remain internal to the cluster. You want the ability to configure each microservice with a specific number of replicas. You also want the ability to address a specific microservice from any other microservice in a uniform way, regardless of the number of replicas the microservice scales to. You plan to implement this solution on Google Kubernetes Engine. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Deploy each microservice as a Deployment. Expose the Deployment in the cluster using an Ingress, and use the Ingress IP address to address the Deployment from other microservices within the cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy each microservice as a Pod. Expose the Pod in the cluster using a Service, and use the Service DNS name to address the microservice from other microservices within the cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Deploy each microservice as a Pod. Expose the Pod in the cluster using an Ingress, and use the Ingress IP address to address the Pod from other microservices within the cluster.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an analytics application that runs hundreds of queries on BigQuery every few minutes using BigQuery API. You want to find out how much time these queries take to execute. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use Stackdriver Monitoring to plot slot usage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Stackdriver Trace to plot API execution time.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use Stackdriver Trace to plot query execution time.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Use Stackdriver Monitoring to plot query execution times.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that will store and access sensitive unstructured data objects in a Cloud Storage bucket. To comply with regulatory requirements, you need to ensure that all data objects are available for at least 7 years after their initial creation. Objects created more than 3 years ago are accessed very infrequently (less than once a year). You need to configure object storage while ensuring that storage cost is optimized. What should you do? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Set a retention policy on the bucket with a period of 7 years.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use IAM Conditions to provide access to objects 7 years after the object creation date.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Enable Object Versioning to prevent objects from being accidentally deleted for 7 years after object creation.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create an object lifecycle policy on the bucket that moves objects from Standard Storage to Archive Storage after 3 years.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Implement a Cloud Function that checks the age of each object in the bucket and moves the objects older than 3 years to a second bucket with the Archive Storage class. Use Cloud Scheduler to trigger the Cloud Function on a daily schedule.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You migrated your applications to Google Cloud Platform and kept your existing monitoring platform. You now find that your notification system is too slow for time critical problems. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Replace your entire monitoring platform with Stackdriver.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Install the Stackdriver agents on your Compute Engine instances.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use Stackdriver to capture and alert on logs, then ship them to your existing platform.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Migrate some traffic back to your old platform and perform A/B testing on the two platforms concurrently.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You want to view the memory usage of your application deployed on Compute Engine. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Install the Stackdriver Client Library.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Install the Stackdriver Monitoring Agent.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use the Stackdriver Metrics Explorer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use the Google Cloud Platform Console.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company's security team utilizes Identity and Access Management (IAM) to monitor user access to resources. You need to establish a version control system that can seamlessly integrate with your security team's processes. Your solution should accommodate rapid release cycles and frequent merges into the main branch to minimize merge conflicts. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Create a Cloud Source Repositories repository and implement trunk-based development.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a Cloud Source Repositories repository and implement feature-based development.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a GitHub repository, mirror it to a Cloud Source Repositories repository, and implement trunk-based development.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a GitHub repository, mirror it to a Cloud Source Repositories repository, and implement feature-based development.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have deployed a Java application to Cloud Run. Your application requires access to a database hosted on Cloud SQL. Due to regulatory requirements, your connection to the Cloud SQL instance must use its internal IP address. How should you configure the connectivity while following Google-recommended best practices?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Configure your Cloud Run service with a Cloud SQL connection.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Configure your Cloud Run service to use a Serverless VPC Access connector.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Configure your application to use the Cloud SQL Java connector.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Configure your application to connect to an instance of the Cloud SQL Auth proxy.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You need to deploy resources from your laptop to Google Cloud using Terraform. Resources in your Google Cloud environment must be created using a service account. Your Cloud Identity has the roles/iam.serviceAccountTokenCreator Identity and Access Management (IAM) role and the necessary permissions to deploy the resources using Terraform. You want to set up your development environment to deploy the desired resources following Google-recommended best practices. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>1. Download the service account’s key file in JSON format, and store it locally on your laptop.
2. Set the GOOGLE_APPLICATION_CREDENTIALS environment variable to the path of your downloaded key file.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>1. Run the following command from a command line: gcloud config set auth/impersonate_service_account service-account-name@project.iam.gserviceacccount.com.
2. Set the GOOGLE_OAUTH_ACCESS_TOKEN environment variable to the value that is returned by the gcloud auth print-access-token command.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Run the following command from a command line: gcloud auth application-default login.
2. In the browser window that opens, authenticate using your personal credentials.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Store the service account’s key file in JSON format in Hashicorp Vault.
2. Integrate Terraform with Vault to retrieve the key file dynamically, and authenticate to Vault using a short-lived access token.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You need to deploy an internet-facing microservices application to Google Kubernetes Engine (GKE). You want to validate new features using the A/B testing method. You have the following requirements for deploying new container image releases:
- There is no downtime when new container images are deployed.
- New production releases are tested and verified using a subset of production users.
What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>1. Configure your CI/CD pipeline to update the Deployment manifest file by replacing the container version with the latest version.
2. Recreate the Pods in your cluster by applying the Deployment manifest file.
3. Validate the application's performance by comparing its functionality with the previous release version, and roll back if an issue arises.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Create a second namespace on GKE for the new release version.
2. Create a Deployment configuration for the second namespace with the desired number of Pods.
3. Deploy new container versions in the second namespace.
4. Update the Ingress configuration to route traffic to the namespace with the new container versions.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>1. Install the Anthos Service Mesh on your GKE cluster.
2. Create two Deployments on the GKE cluster, and label them with different version names.
3. Implement an Istio routing rule to send a small percentage of traffic to the Deployment that references the new version of the application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Implement a rolling update pattern by replacing the Pods gradually with the new release version.
2. Validate the application's performance for the new subset of users during the rollout, and roll back if an issue arises.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You need to copy directory local-scripts and all of its contents from your local workstation to a Compute Engine virtual machine instance. Which command should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. gsutil cp --project "my-gcp-project" -r ~/local-scripts/ gcp-instance-name:~/server-scripts/ --zone "us-east1-b"</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. gsutil cp --project "my-gcp-project" -R ~/local-scripts/ gcp-instance-name:~/server-scripts/ --zone "us-east1-b"</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. gcloud compute scp --project "my-gcp-project" --recurse ~/local-scripts/ gcp-instance-name:~/server-scripts/ --zone "us-east1-b"</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. gcloud compute mv --project "my-gcp-project" --recurse ~/local-scripts/ gcp-instance-name:~/server-scripts/ --zone "us-east1-b"</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are deploying a Python application to Cloud Run using Cloud Source Repositories and Cloud Build. The Cloud Build pipeline is shown below:
```
steps:
- name: python
entrypoint: pip
args: ["install", "-r", "requirements.txt", "--user"]
 
-name: 'gcr.io/cloud-builders/docker'
args: ['build', '-t',
'us-centrall-docker.pkg.dev/$(PROJECT_ID)/$_REPO_NAME}/myimage: $(SHORT_SHA}', '.']
 
- name: 'gcr.io/cloud-builders/docker'
args: ['push',
'us-centrall-docker.pkg.dev/${PROJECT_ID}/$(_REPO_NAME}/myimage: $(SHORT_SHA)']
 
- name: 'google/cloud-sdk'
args: ['gcloud', 'run', 'deploy', 'helloworld-$(SHORT_SHA)',
'--image-us-centrall-docker.pkg.dev/${PROJECT_ID)/$(_REPO_NAME)/myimage: $(SHORT_SHA)',
'--region', 'us-centrall', '--platform', 'managed',
'--allow-unauthenticated']
```
You want to optimize deployment times and avoid unnecessary steps. What should you do?
</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Remove the step that pushes the container to Artifact Registry.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Deploy a new Docker registry in a VPC, and use Cloud Build worker pools inside the VPC to run the build pipeline.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Store image artifacts in a Cloud Storage bucket in the same region as the Cloud Run instance.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Add the --cache-from argument to the Docker build step in your build config file.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team manages a Google Kubernetes Engine (GKE) cluster where an application is running. A different team is planning to integrate with this application. Before they start the integration, you need to ensure that the other team cannot make changes to your application, but they can deploy the integration on GKE. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Using Identity and Access Management (IAM), grant the Viewer IAM role on the cluster project to the other team.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a new GKE cluster. Using Identity and Access Management (IAM), grant the Editor role on the cluster project to the other team.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a new namespace in the existing cluster. Using Identity and Access Management (IAM), grant the Editor role on the cluster project to the other team.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create a new namespace in the existing cluster. Using Kubernetes role-based access control (RBAC), grant the Admin role on the new namespace to the other team.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your service adds text to images that it reads from Cloud Storage. During busy times of the year, requests to Cloud Storage fail with an HTTP 429 "Too Many Requests" status code. How should you handle this error?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Add a cache-control header to the objects.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Request a quota increase from the GCP Console.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Retry the request with a truncated exponential backoff strategy.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Change the storage class of the Cloud Storage bucket to Multi-regional.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company wants to expand their users outside the United States for their popular application. The company wants to ensure 99.999% availability of the database for their application and also wants to minimize the read latency for their users across the globe. Which two actions should they take? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Create a multi-regional Cloud Spanner instance with "nam-asia-eur1" configuration.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a multi-regional Cloud Spanner instance with "nam3" configuration.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Create a cluster with at least 3 Spanner nodes.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a cluster with at least 1 Spanner node.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Create a minimum of two Cloud Spanner instances in separate regions with at least one node.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>F. Create a Cloud Dataflow pipeline to replicate data across different databases.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team has developed an application hosted on a Google Kubernetes Engine (GKE) cluster. You now face the task of establishing a connection between your application and a legacy REST service, which is deployed across two GKE clusters situated in different regions. Your goal is to ensure that this connection is resilient while minimizing the number of required steps. Additionally, you need the ability to perform probe-based health checks on the legacy service using a separate port. How should you configure this connection? (Select two options.)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use Traffic Director with a sidecar proxy to connect the application to the service.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Set up a proxyless Traffic Director configuration for the application.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Configure the legacy service's firewall to allow health checks originating from the sidecar proxy.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Configure the legacy service's firewall to allow health checks originating from the application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Configure the legacy service's firewall to allow health checks originating from the Traffic Director control plane.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You oversee a system that operates on stateless Compute Engine VMs and Cloud Run instances. Specifically, Cloud Run is integrated with a Virtual Private Cloud (VPC), and its ingress setting is configured as Internal. Your objective is to schedule tasks on Cloud Run. To achieve this, you have established a service account and assigned it the roles/run.invoker Identity and Access Management (IAM) role. However, when you attempt to create and test a schedule, you encounter a "403 Permission Denied" error in Cloud Logging. What steps should you take to address this issue?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Grant the service account the roles/run.developer IAM role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Configure a cron job on the Compute Engine VMs to trigger Cloud Run on schedule.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Change the Cloud Run ingress setting to 'Internal and Cloud Load Balancing.'</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Use Cloud Scheduler with Pub/Sub to invoke Cloud Run.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are tasked with building and deploying a microservice for an application hosted on Google Cloud using C++. The code needs to be containerized and use several custom software libraries that your team has built. You do not want to maintain the underlying infrastructure of the application. How should you deploy the microservice?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use Cloud Functions to deploy the microservice.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Use Cloud Build to create the container and deploy it on Cloud Run.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use Cloud Shell to containerize your microservice and deploy it on a Container-Optimized OS Compute Engine instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use Cloud Shell to containerize your microservice and deploy it on standard Google Kubernetes Engine.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have recently developed an application that monitors a large number of stock prices. You need to configure Pub/Sub to receive messages and update the current stock price in an in-memory database. A downstream service requires the most up-to-date prices in the in-memory database for stock trading transactions. Each message contains three pieces of information:
- Stock symbol
- Stock price
- Timestamp for the update
How should you configure your Pub/Sub subscription?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a push subscription with exactly-once delivery enabled.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a pull subscription with both ordering and exactly-once delivery turned off.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a pull subscription with ordering enabled, using the stock symbol as the ordering key.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a push subscription with both ordering and exactly-once delivery turned off.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are defining your system tests for an application running in Cloud Run within a Google Cloud project. You need to create an isolated testing environment separate from the production environment. You want to fully automate the testing environment's creation with minimal effort and run automated tests. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use Cloud Build to execute Terraform scripts that create a new Google Cloud project and a Cloud Run instance of your application within that project.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Cloud Build to execute a Terraform script for deploying a new Cloud Run revision in the existing Google Cloud project. Implement traffic splitting to direct traffic to your test environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use Cloud Build to execute gcloud commands to establish a new Google Cloud project and deploy a Cloud Run instance of your application within it.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use Cloud Build to execute gcloud commands for deploying a new Cloud Run revision in the existing Google Cloud project. Implement traffic splitting to route traffic to your test environment.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You recently developed a web application to transfer log data to a Cloud Storage bucket daily. Authenticated users will regularly review logs from the prior two weeks for critical events. After that, logs will be reviewed once annually by an external auditor. Data must be stored for a period of no less than 7 years. You want to propose a storage solution that meets these requirements and minimizes costs. What should you do? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use the Bucket Lock feature to set the retention policy on the data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Run a scheduled job to set the storage class to Coldline for objects older than 14 days.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a JSON Web Token (JWT) for users needing access to the Coldline storage buckets.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create a lifecycle management policy to set the storage class to Coldline for objects older than 14 days.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Create a lifecycle management policy to set the storage class to Nearline for objects older than 14 days.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company just experienced a Google Kubernetes Engine (GKE) API outage due to a zone failure. You want to deploy a highly available GKE architecture that minimizes service interruption to users in the event of a future zone failure. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Deploy Zonal clusters</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Deploy Regional clusters</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy Multi-Zone clusters</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Deploy GKE on-premises clusters</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an event-driven application. You have created a topic to receive messages sent to Pub/Sub. You want those messages to be processed in real time. You need the application to be independent from any other system and only incur costs when new messages arrive. How should you configure the architecture?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Deploy the application on Compute Engine. Use a Pub/Sub push subscription to process new messages in the topic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Deploy your code on Cloud Functions. Use a Pub/Sub trigger to invoke the Cloud Function. Use the Pub/Sub API to create a pull subscription to the Pub/Sub topic and read messages from it.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy the application on Google Kubernetes Engine. Use the Pub/Sub API to create a pull subscription to the Pub/Sub topic and read messages from it.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Deploy your code on Cloud Functions. Use a Pub/Sub trigger to handle new messages in the topic.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You manage an ecommerce application that processes purchases from customers who can subsequently cancel or change those purchases. You discover that order volumes are highly variable and the backend order-processing system can only process one request at a time. You want to ensure seamless performance for customers regardless of usage volume. It is crucial that customers' order update requests are performed in the sequence in which they were generated. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Send the purchase and change requests over WebSockets to the backend.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Send the purchase and change requests as REST requests to the backend.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use a Pub/Sub subscriber in pull mode and use a data store to manage ordering.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use a Pub/Sub subscriber in push mode and use a data store to manage ordering.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company’s development teams want to use various open source operating systems in their Docker builds. When images are created in published containers in your company’s environment, you need to scan them for Common Vulnerabilities and Exposures (CVEs). The scanning process must not impact software development agility. You want to use managed services where possible. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Enable the Vulnerability scanning setting in the Container Registry.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a Cloud Function that is triggered on a code check-in and scan the code for CVEs.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Disallow the use of non-commercially supported base images in your development environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use Cloud Monitoring to review the output of Cloud Build to determine whether a vulnerable version has been used.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an application deployed in production. When a new version is deployed, you want to ensure that all production traffic is routed to the new version of your application. You also want to keep the previous version deployed so that you can revert to it if there is an issue with the new version. Which deployment strategy should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Blue/green deployment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Canary deployment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Rolling deployment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Recreate deployment</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your application is running as a container in a Google Kubernetes Engine (GKE) cluster. You need to add a secret to your application using a secure approach that prevents the secret being revealed by calls to the Kubernetes API server. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a Kubernetes Secret, and pass the Secret as an environment variable to the container.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Enable GKE Application-layer Secrets Encryption on the cluster using a Cloud Key Management Service (KMS) key.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Store the Secret in Cloud KMS. Create a Google service account to read the Secret from Cloud KMS. Export the service account key in JSON format, and mount the JSON file on the container as a ConfigMap volume which can read the Secret from Cloud KMS.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Store the Secret in Secret Manager. Create a Google service account to read the Secret from Secret Manager. Create a Kubernetes service account to run the container. Use Workload Identity to authenticate as the Google service account.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You configured your Compute Engine instance group to scale automatically according to overall CPU usage. However, your application’s response latency increases sharply before the cluster has finished adding up instances. You want to provide a more consistent latency experience for your end users by changing the configuration of the instance group autoscaler. Which two configuration changes should you make? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Add the label AUTOSCALE to the instance group template.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Decrease the cool-down period for instances added to the group.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Increase the target CPU usage for the instance group autoscaler.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Decrease the target CPU usage for the instance group autoscaler.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Remove the health-check for individual VMs in the instance group.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team manages a large Google Kubernetes Engine (GKE) cluster. Several application teams currently use the same namespace to develop microservices for the cluster. Your organization plans to onboard additional teams to create microservices. You need to configure multiple environments while ensuring the security and optimal performance of each team’s work. You want to minimize cost and follow Google-recommended best practices. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Create new role-based access controls (RBAC) for each team in the existing cluster, and define resource quotas.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a new namespace for each environment in the existing cluster, and define resource quotas.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a new GKE cluster for each team.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a new namespace for each team in the existing cluster, and define resource quotas.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing a marquee stateless web application that will run on Google Cloud. The rate of the incoming user traffic is expected to be unpredictable, with no traffic on some days and large spikes on other days. You need the application to automatically scale up and down, and you need to minimize the cost associated with running the application. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Build the application in Python with Firestore as the database. Deploy the application to Cloud Run.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Build the application in C# with Firestore as the database. Deploy the application to App Engine flexible environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Build the application in Python with CloudSQL as the database. Deploy the application to App Engine standard environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Build the application in Python with Firestore as the database. Deploy the application to a Compute Engine managed instance group with autoscaling.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your website is deployed on a Compute Engine. Your marketing team wants to test conversion rates between 3 different website designs. Which approach should you use?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Deploy the website on App Engine and use traffic splitting.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Deploy the website on App Engine as three separate services.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy the website on Cloud Functions and use traffic splitting.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Deploy the website on Cloud Functions as three separate functions.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are in the final stage of migrating an on-premises data center to Google Cloud. You are quickly approaching your deadline, and discover that a web API is running on a server slated for decommissioning. You need to recommend a solution to modernize this API while migrating to Google Cloud. The modernized web API must meet the following requirements:
- Autoscales during high traffic periods at the end of each month
- Written in Python 3.x
- Developers must be able to rapidly deploy new versions in response to frequent code changes. You want to minimize cost, effort, and operational overhead of this migration.
What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Modernize the code and deploy it on App Engine flexible environment.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Modernize the code and deploy it on App Engine standard environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Modernize the code and deploy the application to an n1-standard-1 Compute Engine instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Ask the development team to rewrite the application to run as a Docker container on Google Kubernetes Engine.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that needs to store files belonging to users in Cloud Storage. You want each user to have their own subdirectory in Cloud Storage. When a new user is created, the corresponding empty subdirectory should also be created. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Create an object with the name of the subdirectory ending with a trailing slash (‘/’) that is zero bytes in length.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create an object with the name of the subdirectory, and then immediately delete the object within that subdirectory.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create an object with the name of the subdirectory that is zero bytes in length and has WRITER access control list permission.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create an object with the name of the subdirectory that is zero bytes in length. Set the Content-Type metadata to CLOUDSTORAGE_FOLDER.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your application is deployed in a Google Kubernetes Engine (GKE) cluster.
When a new version of your application is released, your CI/CD tool updates the spec.template.spec.containers[0].image value to reference the Docker image of your new application version. When the Deployment object applies the change, you want to deploy at least 1 replica of the new version and maintain the previous replicas until the new replica is healthy.
Which change should you make to the GKE Deployment object shown below?
```
apiVersion: apps/v1
kind: Deployment
metadata:
    name: ecommerce-frontend-deployme
spec:
    replicas: 3
    selector:
        matchLabels:
            app: ecommerce-frontend
    template:
        metadata:
            labels:
                app: ecommerce-frontend
spec:
    containers
        name: ecommerce-frontend-webapp
        image: ecommerce-frontend-webapp:1.7.9
        ports:
            containerPort: 80
```
</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Set the Deployment strategy to RollingUpdate with maxSurge set to 0, maxUnavailable set to 1.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Set the Deployment strategy to RollingUpdate with maxSurge set to 1, maxUnavailable set to 0.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Set the Deployment strategy to Recreate with maxSurge set to 0, maxUnavailable set to 1.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Set the Deployment strategy to Recreate with maxSurge set to 1, maxUnavailable set to 0.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing a web application that will be accessible over both HTTP and HTTPS and will run on Compute Engine instances. On occasion, you will need to SSH from your remote laptop into one of the Compute Engine instances to conduct maintenance on the app. How should you configure the instances while following Google-recommended best practices?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Set up a backend with Compute Engine web server instances with a private IP address behind a TCP proxy load balancer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Configure the firewall rules to allow all ingress traffic to connect to the Compute Engine web servers, with each server having a unique external IP address.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Configure Cloud Identity-Aware Proxy API for SSH access. Then configure the Compute Engine servers with private IP addresses behind an HTTP(s) load balancer for the application web traffic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Set up a backend with Compute Engine web server instances with a private IP address behind an HTTP(S) load balancer. Set up a bastion host with a public IP address and open firewall ports. Connect to the web instances using the bastion host.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your development team has been tasked with maintaining a .NET legacy application. The application incurs occasional changes and was recently updated. Your goal is to ensure that the application provides consistent results while moving through the CI/CD pipeline from environment to environment. You want to minimize the cost of deployment while making sure that external factors and dependencies between hosting environments are not problematic. Containers are not yet approved in your organization. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Rewrite the application using .NET Core, and deploy to Cloud Run. Use revisions to separate the environments.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Use Cloud Build to deploy the application as a new Compute Engine image for each build. Use this image in each environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy the application using MS Web Deploy, and make sure to always use the latest, patched MS Windows Server base image in Compute Engine.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use Cloud Build to package the application, and deploy to a Google Kubernetes Engine cluster. Use namespaces to separate the environments.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an application controlled by a managed instance group. When you deploy a new version of the application, costs should be minimized and the number of instances should not increase. You want to ensure that, when each new instance is created, the deployment only continues if the new instance is healthy. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Perform a rolling-action with maxSurge set to 1, maxUnavailable set to 0.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Perform a rolling-action with maxSurge set to 0, maxUnavailable set to 1</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Perform a rolling-action with maxHealthy set to 1, maxUnhealthy set to 0.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Perform a rolling-action with maxHealthy set to 0, maxUnhealthy set to 1.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are working on a new application that is deployed on Cloud Run and uses Cloud Functions. Each time new features are added, new Cloud Functions and Cloud Run services are deployed. You use ENV variables to keep track of the services and enable interservice communication, but maintaining the ENV variables has become difficult. You want to implement dynamic discovery in a scalable way. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Configure your microservices to use the Cloud Run Admin and Cloud Functions APIs to query for deployed Cloud Run services and Cloud Functions in the Google Cloud project.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Create a Service Directory namespace. Use API calls to register the services during deployment, and query during runtime.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Rename the Cloud Functions and Cloud Run services' endpoints using a well-documented naming convention.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Deploy Hashicorp Consul on a single Compute Engine instance. Register the services with Consul during deployment, and query during runtime.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an ecommerce web application that uses App Engine standard environment and Memorystore for Redis. When a user logs into the app, the application caches the user's information (e.g., session, name, address, preferences), which is stored for quick retrieval during checkout. While testing your application in a browser, you get a 502 Bad Gateway error. You have determined that the application is not connecting to Memorystore. What is the reason for this error?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Your Memorystore for Redis instance was deployed without a public IP address.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. You configured your Serverless VPC Access connector in a different region than your App Engine instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. The firewall rule allowing a connection between App Engine and Memorystore was removed during an infrastructure update by the DevOps team.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. You configured your application to use a Serverless VPC Access connector on a different subnet in a different availability zone than your App Engine instance.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your application is built as a custom machine image. You have multiple unique deployments of the machine image. Each deployment is a separate managed instance group with its own template. Each deployment requires a unique set of configuration values. You want to provide these unique values to each deployment but use the same custom machine image in all deployments. You want to use out-of-the-box features of Compute Engine. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Place the unique configuration values in the persistent disk.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Place the unique configuration values in a Cloud Bigtable table.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Place the unique configuration values in the instance template startup script.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Place the unique configuration values in the instance template instance metadata.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>This architectural diagram depicts a system that streams data from thousands of devices. You want to ingest data into a pipeline, store the data, and analyze the data using SQL statements. Which Google Cloud services should you use for steps 1 (ingest), 2 (pipeline), 3 (transaction DB), and 4 (analytics)?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. 1. App Engine 2. Pub/Sub 3. BigQuery 4. Firestore</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. 1. Dataflow 2. Pub/Sub 3. Firestore 4. BigQuery</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. 1. Pub/Sub 2. Dataflow 3. BigQuery 4. Firestore</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. 1. Pub/Sub 2. Dataflow 3. Firestore 4. BigQuery</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You want to create `fully baked` or `golden` Compute Engine images for your application. You need to bootstrap your application to connect to the appropriate database according to the environment the application is running on (test, staging, production). What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Embed the appropriate database connection string in the image. Create a different image for each environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. When creating the Compute Engine instance, add a tag with the name of the database to be connected. In your application, query the Compute Engine API to pull the tags for the current instance, and use the tag to construct the appropriate database connection string.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. When creating the Compute Engine instance, create a metadata item with a key of DATABASE and a value for the appropriate database connection string. In your application, read the DATABASE environment variable, and use the value to connect to the appropriate database.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. When creating the Compute Engine instance, create a metadata item with a key of DATABASE and a value for the appropriate database connection string. In your application, query the metadata server for the DATABASE value, and use the value to connect to the appropriate database.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company is planning to migrate their on-premises Hadoop environment to the cloud. Increasing storage cost and maintenance of data stored in HDFS is a major concern for your company. You also want to make minimal changes to existing data analytics jobs and existing architecture. How should you proceed with the migration?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Migrate your data stored in Hadoop to BigQuery. Change your jobs to source their information from BigQuery instead of the on-premises Hadoop environment.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create Compute Engine instances with HDD instead of SSD to save costs. Then perform a full migration of your existing environment into the new one in Compute Engine instances.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a Cloud Dataproc cluster on Google Cloud Platform, and then migrate your Hadoop environment to the new Cloud Dataproc cluster. Move your HDFS data into larger HDD disks to save on storage costs.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create a Cloud Dataproc cluster on Google Cloud Platform, and then migrate your Hadoop code objects to the new cluster. Move your data to Cloud Storage and leverage the Cloud Dataproc connector to run jobs on that data.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are building an application that uses a distributed microservices architecture. You want to measure the performance and system resource utilization in one of the microservices written in Java. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Instrument the service with Cloud Profiler to measure CPU utilization and method-level execution times in the service.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Instrument the service with Debugger to investigate service errors.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Instrument the service with Cloud Trace to measure request latency.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Instrument the service with OpenCensus to measure service latency, and write custom metrics to Cloud Monitoring.</detail>
        </option>
      </options>
    </answer>
  </entry> 
</bank>