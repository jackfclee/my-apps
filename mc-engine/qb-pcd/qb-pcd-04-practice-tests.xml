<?xml version="1.0" encoding="UTF-8"?>
<bank>
  <topic>PCA01 - Brain Dump</topic>
  <!-- STRUCTURE DEFINITION:
  <entry>
    <question>XXX</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>XXX</detail>
        </option>
      </options>
    </answer>
  </entry> 
  -->
  <entry>
    <question>Before promoting your new application code to production, you want to conduct testing across a variety of different users. Although this plan is risky, you want to test the new version of the application with production users and you want to control which users are forwarded to the new version of the application based on their operating system. If bugs are discovered in the new version, you want to roll back the newly deployed version of the application as quickly as possible. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Deploy your application on Cloud Run. Use traffic splitting to direct a subset of user traffic to the new version based on the revision tag.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Deploy your application on Google Kubernetes Engine with Anthos Service Mesh. Use traffic splitting to direct a subset of user traffic to the new version based on the user-agent header.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Deploy your application on App Engine. Use traffic splitting to direct a subset of user traffic to the new version based on the IP address.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Deploy your application on Compute Engine. Use Traffic Director to direct a subset of user traffic to the new version based on predefined weights.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are designing a deployment technique for your new applications on Google Cloud. As part of your deployment planning, you want to use live traffic to gather performance metrics for both new and existing applications. You need to test against the full production load prior to launch. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use canary deployment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use blue/green deployment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use rolling updates deployment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use A/B testing with traffic mirroring during deployment</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a developer at a large organization. You are deploying a web application to Google Kubernetes Engine (GKE). The DevOps team has built a CI/CD pipeline that uses Cloud Deploy to deploy the application to Dev, Test, and Prod clusters in GKE. After Cloud Deploy successfully deploys the application to the Dev cluster, you want to automatically promote it to the Test cluster. How should you configure this process following Google-recommended best practices?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>1. Create a Cloud Build trigger that listens for SUCCEEDED Pub/Sub messages from the clouddeploy-operations topic.
2. Configure Cloud Build to include a step that promotes the application to the Test cluster.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Create a Cloud Function that calls the Google Cloud Deploy API to promote the application to the Test cluster.
2. Configure this function to be triggered by SUCCEEDED Pub/Sub messages from the cloud-builds topic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Create a Cloud Function that calls the Google Cloud Deploy API to promote the application to the Test cluster.
2. Configure this function to be triggered by SUCCEEDED Pub/Sub messages from the clouddeploy-operations topic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Create a Cloud Build pipeline that uses the gke-deploy builder.
2. Create a Cloud Build trigger that listens for SUCCEEDED Pub/Sub messages from the cloud-builds topic.
3. Configure this pipeline to run a deployment step to the Test cluster.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company has a data warehouse that keeps your application information in BigQuery. The BigQuery data warehouse keeps 2 PBs of user data. Recently, your company expanded your user base to include EU users and needs to comply with these requirements:
- Your company must be able to delete all user account information upon user request.
- All EU user data must be stored in a single region specifically for EU users.
Which two actions should you take? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use BigQuery federated queries to query data from Cloud Storage.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Create a dataset in the EU region that will keep information about EU users only.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a Cloud Storage bucket in the EU region to store information for EU users only.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Re-upload your data using a Cloud Dataflow pipeline by filtering your user records out.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>E. Use DML statements in BigQuery to update/delete user records based on their requests.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team is responsible for maintaining an application that aggregates news articles from many different sources. Your monitoring dashboard contains publicly accessible real-time reports and runs on a Compute Engine instance as a web application. External stakeholders and analysts need to access these reports via a secure channel without authentication. How should you configure this secure channel?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Add a public IP address to the instance. Use the service account key of the instance to encrypt the traffic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Cloud Scheduler to trigger Cloud Build every hour to create an export from the reports. Store the reports in a public Cloud Storage bucket.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Add an HTTP(S) load balancer in front of the monitoring dashboard. Configure Identity-Aware Proxy to secure the communication channel.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Add an HTTP(S) load balancer in front of the monitoring dashboard. Set up a Google-managed SSL certificate on the load balancer for traffic encryption.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are using Cloud Run to host a web application. You need to securely obtain the application project ID and region where the application is running and display this information to users. You want to use the most performant approach.What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use HTTP requests to query the available metadata server at the http://metadata.google.internal/ endpoint with the Metadata-Flavor: Google header.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. In the Google Cloud console, navigate to the Project Dashboard and gather configuration details. Navigate to the Cloud Run “Variables & Secrets” tab, and add the desired environment variables in Key:Value format.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. In the Google Cloud console, navigate to the Project Dashboard and gather configuration details. Write the application configuration information to Cloud Run's in-memory container filesystem.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Make an API call to the Cloud Asset Inventory API from the application and format the request to include instance metadata.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team develops services that run on Google Cloud. You want to process messages sent to a Pub/Sub topic, and then store them. Each message must be processed exactly once to avoid duplication of data and any data conflicts. You need to use the cheapest and most simple solution. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Process the messages with a Dataproc job, and write the output to storage.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Process the messages with a Dataflow streaming pipeline using Apache Beam's PubSubIO package, and write the output to storage.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Process the messages with a Cloud Function, and write the results to a BigQuery location where you can run a job to deduplicate the data.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Retrieve the messages with a Dataflow streaming pipeline, store them in Cloud Bigtable, and use another Dataflow streaming pipeline to deduplicate messages.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company stores their source code in a Cloud Source Repositories repository. Your company wants to build and test their code on each source code commit to the repository and requires a solution that is managed and has minimal operations overhead. Which method should they use?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use Cloud Build with a trigger configured for each source code commit.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Jenkins deployed via the Google Cloud Platform Marketplace, configured to watch for source code commits.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use a Compute Engine virtual machine instance with an open source continuous integration tool, configured to watch for source code commits.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use a source code commit trigger to push a message to a Cloud Pub/Sub topic that triggers an App Engine service to build the source code.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your analytics system executes queries against a BigQuery dataset. The SQL query is executed in batch and passes the contents of a SQL file to the BigQuery CLI. Then it redirects the BigQuery CLI output to another process. However, you are getting a permission error from the BigQuery CLI when the queries are executed. You want to resolve the issue. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Grant the service account BigQuery Data Viewer and BigQuery Job User roles.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Grant the service account BigQuery Data Editor and BigQuery Data Viewer roles.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a view in BigQuery from the SQL query and SELECT* from the view in the CLI.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a new dataset in BigQuery, and copy the source table to the new dataset Query the new dataset and table from the CLI.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You manage a microservices application on Google Kubernetes Engine (GKE) using Istio. You secure the communication channels between your microservices by implementing an Istio AuthorizationPolicy, a Kubernetes NetworkPolicy, and mTLS on your GKE cluster. You discover that HTTP requests between two Pods to specific URLs fail, while other requests to other URLs succeed. What is the cause of the connection issue?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. A Kubernetes NetworkPolicy resource is blocking HTTP traffic between the Pods.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. The Pod initiating the HTTP requests is attempting to connect to the target Pod via an incorrect TCP port.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. The Authorization Policy of your cluster is blocking HTTP requests for specific paths within your application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. The cluster has mTLS configured in permissive mode, but the Pod's sidecar proxy is sending unencrypted traffic in plain text.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are deploying your application to a Compute Engine virtual machine instance. Your application is configured to write its log files to disk. You want to view the logs in Cloud Logging without changing the application code. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Install the Cloud Logging Agent and configure it to send the application logs.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use a Cloud Logging Library to log directly from the application to Cloud Logging.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Provide the log file folder path in the metadata of the instance to configure it to send the application logs.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Change the application to log to /var/log so that its logs are automatically sent to Cloud Logging.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You need to build a public API that authenticates, enforces quotas, and reports metrics for API callers. 
```
the client ::: cloud load balancer ::: ??? ::: PHP application
```
Which tool should you use to complete this architecture?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. App Engine</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Cloud Endpoints</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Identity-Aware Proxy</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. GKE Ingress for HTTP(S) Load Balancing</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are parsing a log file that contains three columns: a timestamp, an account number (a string), and a transaction amount (a number). You want to calculate the sum of all transaction amounts for each unique account number efficiently. Which data structure should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. A linked list</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. A hash table</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. A two-dimensional array</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. A comma-separated string</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your company has created an application that uploads a report to a Cloud Storage bucket. When the report is uploaded to the bucket, you want to publish a message to a Cloud Pub/Sub topic. You want to implement a solution that will require only a small amount of effort to implement. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Configure the Cloud Storage bucket to trigger Cloud Pub/Sub notifications when objects are modified.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create an App Engine application to receive the file; when it is received, publish a message to the Cloud Pub/Sub topic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a Cloud Function that is triggered by the Cloud Storage bucket. In the Cloud Function, publish a message to the Cloud Pub/Sub topic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create an application deployed in a Google Kubernetes Engine cluster to receive the file; when it is received, publish a message to the Cloud Pub/Sub topic.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are responsible for deploying a new API. That API will have three different URL paths:
- https://yourcompany.com/students
- https://yourcompany.com/teachers
- https://yourcompany.com/classes
You need to configure each API URL path to invoke a different function in your code. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create one Cloud Function as a backend service exposed using an HTTPS load balancer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create three Cloud Functions exposed directly.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create one Cloud Function exposed directly.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create three Cloud Functions as three backend services exposed using an HTTPS load balancer.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are planning to deploy hundreds of microservices in your Google Kubernetes Engine (GKE) cluster. How should you secure communication between the microservices on GKE using a managed service?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use global HTTP(S) Load Balancing with managed SSL certificates to protect your services</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Deploy open source Istio in your GKE cluster, and enable mTLS in your Service Mesh</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Install cert-manager on GKE to automatically renew the SSL certificates.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Install Anthos Service Mesh, and enable mTLS in your Service Mesh.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You work for an organization that manages an ecommerce site. Your application is deployed behind a global HTTP(S) load balancer. You need to test a new product recommendation algorithm. You plan to use A/B testing to determine the new algorithm’s effect on sales in a randomized way. How should you test this feature?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Split traffic between versions using weights.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Enable the new recommendation feature flag on a single instance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Mirror traffic to the new version of your application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use HTTP header-based routing.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are writing a Compute Engine hosted application in project A that needs to securely authenticate to a Cloud Pub/Sub topic in project B. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Configure the instances with a service account owned by project B. Add the service account as a Cloud Pub/Sub publisher to project A.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Configure the instances with a service account owned by project A. Add the service account as a publisher on the topic.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Configure Application Default Credentials to use the private key of a service account owned by project B. Add the service account as a Cloud Pub/Sub publisher to project A.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Configure Application Default Credentials to use the private key of a service account owned by project A. Add the service account as a publisher on the topic</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team develops stateless services that run on Google Kubernetes Engine (GKE). You need to deploy a new service that will only be accessed by other services running in the GKE cluster. The service will need to scale as quickly as possible to respond to changing load. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use a Vertical Pod Autoscaler to scale the containers, and expose them via a ClusterIP Service.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use a Vertical Pod Autoscaler to scale the containers, and expose them via a NodePort Service.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use a Horizontal Pod Autoscaler to scale the containers, and expose them via a ClusterIP Service.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use a Horizontal Pod Autoscaler to scale the containers, and expose them via a NodePort Service.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have two tables in an ANSI-SQL compliant database with identical columns that you need to quickly combine into a single table, removing duplicate rows from the result set. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use the JOIN operator in SQL to combine the tables.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use nested WITH statements to combine the tables.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use the UNION operator in SQL to combine the tables.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use the UNION operator in SQL to combine the tables.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have two Google Cloud projects, named Project A and Project B. You need to create a Cloud Function in Project A that saves the output in a Cloud Storage bucket in Project B. You want to follow the principle of least privilege. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>1. Create a Google service account in Project B.
2. Deploy the Cloud Function with the service account in Project A.
3. Assign this service account the roles/storage.objectCreator role on the storage bucket residing in Project B.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>1. Create a Google service account in Project A
2. Deploy the Cloud Function with the service account in Project A.
3. Assign this service account the roles/storage.objectCreator role on the storage bucket residing in Project B.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Determine the default App Engine service account (PROJECT_ID@appspot.gserviceaccount.com) in Project A.
2. Deploy the Cloud Function with the default App Engine service account in Project A.
3. Assign the default App Engine service account the roles/storage.objectCreator role on the storage bucket residing in Project B.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Determine the default App Engine service account (PROJECT_ID@appspot.gserviceaccount.com) in Project B.
2. Deploy the Cloud Function with the default App Engine service account in Project A.
3. Assign the default App Engine service account the roles/storage.objectCreator role on the storage bucket residing in Project B.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You work for a web development team at a small startup. Your team is developing a Node.js application using Google Cloud services, including Cloud Storage and Cloud Build. The team uses a Git repository for version control. Your manager calls you over the weekend and instructs you to make an emergency update to one of the company's websites, and you're the only developer available. You need to access Google Cloud to make the update, but you don't have your work laptop. You are not allowed to store source code locally on a non-corporate computer. How should you set up your developer environment?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use a text editor and the Git command line to send your source code updates as pull requests from a public computer.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use a text editor and the Git command line to send your source code updates as pull requests from a virtual machine running on a public computer.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use Cloud Shell and the built-in code editor for development. Send your source code updates as pull requests.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use a Cloud Storage bucket to store the source code that you need to edit. Mount the bucket to a public computer as a drive, and use a code editor to update the code. Turn on versioning for the bucket, and point it to the team's Git repository.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are using Cloud Build to build and test application source code stored in Cloud Source Repositories. The build process requires a build tool not available in the Cloud Build environment. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Download the binary from the internet during the build process.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Build a custom cloud builder image and reference the image in your build steps.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Include the binary in your Cloud Source Repositories repository and reference it in your build scripts.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Ask to have the binary added to the Cloud Build environment by filing a feature request against the Cloud Build public Issue Tracker.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You noticed that your application was forcefully shut down during a Deployment update in Google Kubernetes Engine. Your application didn’t close the database connection before it was terminated. You want to update your application to make sure that it completes a graceful shutdown. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Update your code to process a received SIGTERM signal to gracefully disconnect from the database.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Configure a PodDisruptionBudget to prevent the Pod from being forcefully shut down.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Increase the terminationGracePeriodSeconds for your application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Configure a PreStop hook to shut down your application.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You recently developed an application. You need to call the Cloud Storage API from a Compute Engine instance that doesn't have a public IP address. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use Carrier Peering</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use VPC Network Peering</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use Shared VPC networks</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Use Private Google Access</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You work for an organization that manages an online ecommerce website. Your company plans to expand across the world; however, the estore currently serves one specific region. You need to select a SQL database and configure a schema that will scale as your organization grows. You want to create a table that stores all customer transactions and ensure that the customer (CustomerId) and the transaction (TransactionId) are unique. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a Cloud SQL table that has TransactionId and CustomerId configured as primary keys. Use an incremental number for the TransactionId.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a Cloud SQL table that has TransactionId and CustomerId configured as primary keys. Use a random string (UUID) for the TransactionId.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Create a Cloud Spanner table that has TransactionId and CustomerId configured as primary keys. Use a random string (UUID) for the TransactionId.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a Cloud Spanner table that has TransactionId and CustomerId configured as primary keys. Use an incremental number for the TransactionId.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your application is controlled by a managed instance group. You want to share a large read-only data set between all the instances in the managed instance group. You want to ensure that each instance can start quickly and can access the data set via its filesystem with very low latency. You also want to minimize the total cost of the solution. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Move the data to a Cloud Storage bucket, and mount the bucket on the filesystem using Cloud Storage FUSE.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Move the data to a Cloud Storage bucket, and copy the data to the boot disk of the instance via a startup script.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Move the data to a Compute Engine persistent disk, and attach the disk in read-only mode to multiple Compute Engine virtual machine instances.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Move the data to a Compute Engine persistent disk, take a snapshot, create multiple disks from the snapshot, and attach each disk to its own instance.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You work for a financial services company that has a container-first approach. Your team develops microservices applications. A Cloud Build pipeline creates the container image, runs regression tests, and publishes the image to Artifact Registry. You need to ensure that only containers that have passed the regression tests are deployed to Google Kubernetes Engine (GKE) clusters. You have already enabled Binary Authorization on the GKE clusters. What should you do next?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Create an attestor and a policy. After a container image has successfully passed the regression tests, use Cloud Build to run Kritis Signer to create an attestation for the container image.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Deploy Voucher Server and Voucher Client components. After a container image has successfully passed the regression tests, run Voucher Client as a step in the Cloud Build pipeline.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Set the Pod Security Standard level to Restricted for the relevant namespaces. Use Cloud Build to digitally sign the container images that have passed the regression tests.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create an attestor and a policy. Create an attestation for the container images that have passed the regression tests as a step in the Cloud Build pipeline.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your existing application keeps user state information in a single MySQL database. This state information is very user-specific and depends heavily on how long a user has been using an application. The MySQL database is causing challenges to maintain and enhance the schema for various users. Which storage option should you choose?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Cloud SQL</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Cloud Storage</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Cloud Spanner</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Cloud Datastore/Firestore</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are supporting a business-critical application in production deployed on Cloud Run. The application is reporting HTTP 500 errors that are affecting the usability of the application. You want to be alerted when the number of errors exceeds 15% of the requests within a specific time window. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a Cloud Function that consumes the Cloud Monitoring API. Use Cloud Scheduler to trigger the Cloud Function daily and alert you if the number of errors is above the defined threshold.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Navigate to the Cloud Run page in the Google Cloud console, and select the service from the services list. Use the Metrics tab to visualize the number of errors for that revision, and refresh the page daily.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Create an alerting policy in Cloud Monitoring that alerts you if the number of errors is above the defined threshold.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a Cloud Function that consumes the Cloud Monitoring API. Use Cloud Composer to trigger the Cloud Function daily and alert you if the number of errors is above the defined threshold.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your code is running on Cloud Functions in project A. It is supposed to write an object in a Cloud Storage bucket owned by project B. However, the write call is failing with the error "403 Forbidden". What should you do to correct the problem?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Grant your user account the roles/storage.objectCreator role for the Cloud Storage bucket.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Grant your user account the roles/iam.serviceAccountUser role for the service-PROJECTA@gcf-admin-robot.iam.gserviceaccount.com service account.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Grant the service-PROJECTA@gcf-admin-robot.iam.gserviceaccount.com service account the roles/storage.objectCreator role for the Cloud Storage bucket.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Enable the Cloud Storage API in project B.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are building a CI/CD pipeline that consists of a version control system, Cloud Build, and Container Registry. Each time a new tag is pushed to the repository, a Cloud Build job is triggered, which runs unit tests on the new code, builds a new Docker container image, and pushes it into Container Registry. The last step of your pipeline should deploy the new container to your production Google Kubernetes Engine (GKE) cluster. You need to select a tool and deployment strategy that meets the following requirements:
- Zero downtime is incurred
- Testing is fully automated
- Allows for testing before being rolled out to users
- Can quickly rollback if needed
What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Trigger a Spinnaker pipeline configured as an A/B test of your new code, and, if it is successful, deploy the container to production.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Trigger a Spinnaker pipeline configured as a canary test of your new code, and, if it is successful, deploy the container to production.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Trigger another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a canary test.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Trigger another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a shadow test.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team develops services that run on Google Cloud. You need to build a data processing service and will use Cloud Functions. The data to be processed by the function is sensitive. You need to ensure that invocations can only happen from authorized services and follow Google-recommended best practices for securing functions. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Enable Identity-Aware Proxy in your project. Secure function access using its permissions.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a service account with the Cloud Functions Viewer role. Use that service account to invoke the function.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Create a service account with the Cloud Functions Invoker role. Use that service account to invoke the function.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create an OAuth 2.0 client ID for your calling service in the same project as the function you want to secure. Use those credentials to invoke the function.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your development team has built several Cloud Functions using Java along with corresponding integration and service tests. You are building and deploying the functions and launching the tests using Cloud Build. Your Cloud Build job is reporting deployment failures immediately after successfully validating the code. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Check the maximum number of Cloud Function instances.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Verify that your Cloud Build trigger has the correct build parameters.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Retry the tests using the truncated exponential backoff polling strategy.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Verify that the Cloud Build service account is assigned the Cloud Functions Developer role.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are a developer at a large organization. You have an application written in Go running in a production Google Kubernetes Engine (GKE) cluster. You need to add a new feature that requires access to BigQuery. You want to grant BigQuery access to your GKE cluster following Google-recommended best practices. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a Google service account with BigQuery access. Add the JSON key to Secret Manager, and use the Go client library to access the JSON key.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a Google service account with BigQuery access. Add the Google service account JSON key as a Kubernetes secret, and configure the application to use this secret.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a Google service account with BigQuery access. Add the Google service account JSON key to Secret Manager, and use an init container to access the secret for the application to use.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a Google service account and a Kubernetes service account. Configure Workload Identity on the GKE cluster, and reference the Kubernetes service account on the application Deployment.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You recently joined a new team that has a Cloud Spanner database instance running in production. Your manager has asked you to optimize the Spanner instance to reduce cost while maintaining high reliability and availability of the database. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use Cloud Logging to check for error logs, and reduce Spanner processing units by small increments until you find the minimum capacity required.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Use Cloud Monitoring to monitor the CPU utilization, and reduce Spanner processing units by small increments until you find the minimum capacity required.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use Cloud Trace to monitor the requests per sec of incoming requests to Spanner, and reduce Spanner processing units by small increments until you find the minimum capacity required.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Use Snapshot Debugger to check for application errors, and reduce Spanner processing units by small increments until you find the minimum capacity required.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team has created an application that is hosted on a Google Kubernetes Engine (GKE) cluster. You need to connect the application to a legacy REST service that is deployed in two GKE clusters in two different regions. You want to connect your application to the target service in a way that is resilient. You also want to be able to run health checks on the legacy service on a separate port. How should you set up the connection? (Choose two options)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Use Traffic Director with a sidecar proxy to connect the application to the service.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use a proxyless Traffic Director configuration to connect the application to the service.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Configure the legacy service's firewall to allow health checks originating from the proxy.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Configure the legacy service's firewall to allow health checks originating from the application.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>E. Configure the legacy service's firewall to allow health checks originating from the Traffic Director control plane.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You want to notify on-call engineers about a service degradation in production while minimizing development time. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Use Cloud Function to monitor resources and raise alerts.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Cloud Pub/Sub to monitor resources and raise alerts.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Use Cloud Error Reporting to capture errors and raise alerts.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Use Cloud Monitoring to monitor resources and raise alerts.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that consists of several microservices running in a Google Kubernetes Engine cluster. One microservice needs to connect to a third-party database running on-premises. You need to store credentials to the database and ensure that these credentials can be rotated while following security best practices. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Store the credentials in a sidecar container proxy, and use it to connect to the third-party database.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Store the credentials as a Kubernetes Secret, and use the Cloud Key Management Service plugin to handle encryption and decryption.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Store the credentials in an encrypted volume mount, and associate a Persistent Volume Claim with the client Pod.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Configure a service mesh to allow or restrict traffic from the Pods in your microservice to the database.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You have an on-premises application that authenticates to the Cloud Storage API using a user-managed service account with a user-managed key. The application connects to Cloud Storage using Private Google Access over a Dedicated Interconnect link. You discover that requests from the application to access objects in the Cloud Storage bucket are failing with a 403 Permission Denied error code. What is the likely cause of this issue?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. The folder structure inside the bucket and object paths have changed.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. The permissions of the service account’s predefined role have changed.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. The service account key has been rotated but not updated on the application server.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. The Interconnect link from the on-premises data center to Google Cloud is experiencing a temporary outage.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are developing an application that reads credit card data from a Pub/Sub subscription. You have written code and completed unit testing. You need to test the Pub/Sub integration before deploying to Google Cloud. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a service to publish messages, and deploy the Pub/Sub emulator. Generate random content in the publishing service, and publish to the emulator.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a service to publish messages to your application. Collect the messages from Pub/Sub in production, and replay them through the publishing service.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a service to publish messages, and deploy the Pub/Sub emulator. Collect the messages from Pub/Sub in production, and publish them to the emulator.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create a service to publish messages, and deploy the Pub/Sub emulator. Publish a standard set of testing messages from the publishing service to the emulator.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You plan to deploy a new application revision with a Deployment resource to Google Kubernetes Engine (GKE) in production. The container might not work correctly. You want to minimize risk in case there are issues after deploying the revision. You want to follow Google-recommended best practices. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Perform a rolling update with a PodDisruptionBudget of 80%.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Perform a rolling update with a HorizontalPodAutoscaler scale-down policy value of 0.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Convert the Deployment to a StatefulSet, and perform a rolling update with a PodDisruptionBudget of 80%.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Convert the Deployment to a StatefulSet, and perform a rolling update with a HorizontalPodAutoscaler scale-down policy value of 0.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your application performs well when tested locally, but it runs significantly slower after you deploy it to a Compute Engine instance. You need to diagnose the problem. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. File a ticket with Cloud Support indicating that the application performs faster locally.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Use Cloud Debugger snapshots to look at a point-in-time execution of the application.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Use Cloud Profiler to determine which functions within the application take the longest amount of time.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Add logging commands to the application and use Cloud Logging to check where the latency problem occurs.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You migrated some of your applications to Google Cloud. You are using a legacy monitoring platform deployed on-premises for both on-premises and cloud- deployed applications. You discover that your notification system is responding slowly to time-critical problems in the cloud applications. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Replace your monitoring platform with Cloud Monitoring.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Install the Cloud Monitoring agent on your Compute Engine instances.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Migrate some traffic back to your old platform. Perform A/B testing on the two platforms concurrently.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Use Cloud Logging and Cloud Monitoring to capture logs, monitor, and send alerts. Send them to your existing platform.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team is developing a new application using a PostgreSQL database and Cloud Run. You are responsible for ensuring that all traffic is kept private on Google Cloud. You want to use managed services and follow Google-recommended best practices. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>1. Enable Cloud SQL and Cloud Run in the same project.
2. Configure a private IP address for Cloud SQL. Enable private services access.
3. Create a Serverless VPC Access connector.
4. Configure Cloud Run to use the connector to connect to Cloud SQL.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Install PostgreSQL on a Compute Engine virtual machine (VM), and enable Cloud Run in the same project.
2. Configure a private IP address for the VM. Enable private services access.
3. Create a Serverless VPC Access connector.
4. Configure Cloud Run to use the connector to connect to the VM hosting PostgreSQL.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Use Cloud SQL and Cloud Run in different projects.
2. Configure a private IP address for Cloud SQL. Enable private services access.
3. Create a Serverless VPC Access connector.
4. Set up a VPN connection between the two projects. Configure Cloud Run to use the connector to connect to Cloud SQL.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Install PostgreSQL on a Compute Engine VM, and enable Cloud Run in different projects.
2. Configure a private IP address for the VM. Enable private services access.
3. Create a Serverless VPC Access connector.
4. Set up a VPN connection between the two projects. Configure Cloud Run to use the connector to access the VM hosting PostgreSQL</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are running a web application on Google Kubernetes Engine that you inherited. You want to determine whether the application is using libraries with known vulnerabilities or is vulnerable to XSS attacks. Which service should you use?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Google Cloud Armor</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Debugger</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Web Security Scanner</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Error Reporting</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are using the Cloud Client Library to upload an image in your application to Cloud Storage. Users of the application report that occasionally the upload does not complete and the client library reports an HTTP 504 Gateway Timeout error. You want to make the application more resilient to errors. What changes to the application should you make?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A. Write an exponential backoff process around the client library call.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Write a one-second wait time backoff process around the client library call.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Design a retry button in the application and ask users to click if the error occurs.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Create a queue for the object and inform the users that the application will try again in 10 minutes.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You developed a JavaScript web application that needs to access Google Drive's API and obtain permission from users to store files in their Google Drives. You need to select an authorization approach for your application. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create an API key.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Create a SAML token.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Create a service account.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>D. Create an OAuth Client ID.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are deploying your application on a Compute Engine instance that communicates with Cloud SQL. You will use Cloud SQL Proxy to allow your application to communicate to the database using the service account associated with the application's instance. You want to follow the Google-recommended best practice of providing minimum access for the role assigned to the service account. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Assign the Project Editor role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>B. Assign the Project Owner role.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>C. Assign the Cloud SQL Client role.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Assign the Cloud SQL Editor role.</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>Your team is building an application for a financial institution. The application's frontend runs on Compute Engine, and the data resides in Cloud SQL and one Cloud Storage bucket. The application will collect data containing PII, which will be stored in the Cloud SQL database and the Cloud Storage bucket. You need to secure the PII data. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>1. Create the relevant firewall rules to allow only the frontend to communicate with the Cloud SQL database
2. Using IAM, allow only the frontend service account to access the Cloud Storage bucket</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Create the relevant firewall rules to allow only the frontend to communicate with the Cloud SQL database
2. Enable private access to allow the frontend to access the Cloud Storage bucket privately</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Configure a private IP address for Cloud SQL
2. Use VPC-SC to create a service perimeter
3. Add the Cloud SQL database and the Cloud Storage bucket to the same service perimeter</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>1. Configure a private IP address for Cloud SQL
2. Use VPC-SC to create a service perimeter
3. Add the Cloud SQL database and the Cloud Storage bucket to different service perimeters</detail>
        </option>
      </options>
    </answer>
  </entry> 
  <entry>
    <question>You are working on an application that relies on Cloud Spanner as its primary datastore. New application features have, on occasion, caused performance regressions. To prevent performance issues, you want to run an automated performance test with Cloud Build for each commit made. If multiple commits are made simultaneously, the tests may run concurrently. What should you do?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>A. Create a new project with a random name for each build, load the necessary data, and delete the project after the test is completed.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B. Create a new Cloud Spanner instance for each build, load the required data, and delete the Cloud Spanner instance after the test is completed.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C. Set up a project with a Cloud Spanner instance and the required data, and modify the Cloud Build build file to automatically restore the data to its previous state after the test is completed.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>D. Launch the Cloud Spanner emulator locally, load the necessary data, and shut down the emulator after the test is completed.</detail>
        </option>
      </options>
    </answer>
  </entry> 
</bank>