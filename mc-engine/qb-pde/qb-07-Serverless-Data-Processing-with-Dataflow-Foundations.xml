<?xml version='1.0' encoding='UTF-8'?>
<bank>
  <topic>PDE07 - Serverless Data Processing with Dataflow: Foundations</topic>
  <entry>
    <question>What is the Beam Portability Framework?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>A set of protocols for executing pipelines</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>A hermetic worker environment</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>A set of cross-language transforms</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>A language-agnostic way to represent pipelines</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which of the following are benefits of Beam Portability (Select ALL that apply)?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Running pipelines authored in any SDK on any runner</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Implement new Beam transforms using a language of choice and utilize these transforms from other languages</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Cross-language transforms</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>The Dataflow Shuffle service is available only for batch jobs.</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>False</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>True</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which of the following are TRUE about Flexible Resource Scheduling (select ALL that apply) :</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>FlexRS helps to reduce batch processing costs by using advanced scheduling techniques</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>When you submit a FlexRS job, the Dataflow service places the job into a queue and submits it for execution within 6 hours from job creation.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>FlexRS leverages a mix of preemptible and normal VMs</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>FlexRS is most suitable for workloads that are time-critical</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>What are the benefits of Dataflow Streaming Engine? Select ALL that apply:</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Lower resource and quota consumption</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>More responsive autoscaling for incoming data variations</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Reduced consumption of worker CPU, memory, and storage</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>You want to run the following command:
```
gcloud dataflow jobs cancel \
  2021-01-31_14_30_00-9098096469011826084 \
  --region=$REGION
```
Which of these roles can be assigned to you for the command to work?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Dataflow Admin</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Dataflow Developer</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Composer Worker</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Dataflow Viewer</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Your project’s current SSD usage is 100 TB. You want to launch a streaming pipeline with shuffle done on the VM. You set the initial number of workers to 5 and the maximum number of workers to 100. What will be your project’s SSD usage when the job launches?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>500 TB</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>103 TB</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>102 TB</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>140 TB</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>You are a Beam developer for a university in Googleville. Googleville law mandates that all student data is kept within Googleville. 
  Compute Engine resources can be launched in Googleville; the region name is google-world1. 
  Dataflow, however, does not currently have a regional endpoint set up in google-world1. 
  Which flags are needed in the following command to allow you to launch a Dataflow job and to conform with Googleville’s law?
  ```
  python3 -m apache_beam.examples.wordcount \
    --input gs://dataflow-samples/shakespeare/kinglear.txt \
    --output gs://$BUCKET/results/outputs \
    --runner DataflowRunner \
    --project $PROJECT \
    --temp_location gs://$BUCKET/tmp/ \
  ```
    </question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>--region google-world1 --worker_zone google-world1</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>--region northamerica-northeast1</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>--region northamerica-northeast1 --worker_region google-world1</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Your project’s current In-use IP address usage is 500/575. You run the following command:
```
python3 -m apache_beam.examples.wordcount \
--input gs://dataflow-samples/shakespeare/kinglear.txt \
--output gs://$BUCKET/results/outputs \
--runner DataflowRunner \
--project $PROJECT \
--temp_location gs://$BUCKET/tmp/ --region $REGION \
--subnetwork regions/$REGION/subnetworks/$SUBNETWORK \
--num_workers 20 \
--machine_type n1-standard-4 \
--no_use_public_ips
```
What will be the in-use IP address usage after the job starts?
    </question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>The job will fail to launch.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>520/575</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>500/575</detail>
        </option>
      </options>
    </answer>
  </entry>
  <!--
  STRUCTURE DEFINITION:
  <entry>
    <question>XXX</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>XXX</detail>
        </option>
      </options>
    </answer>
  </entry>
  -->
</bank>