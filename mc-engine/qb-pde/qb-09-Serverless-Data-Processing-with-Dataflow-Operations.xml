<?xml version='1.0' encoding='UTF-8'?>
<bank>
  <topic>PDE09 - Serverless Data Processing with Dataflow: Operations</topic>
  <entry>
    <question>You have a Pub/Sub subscription with data that hasn’t been processed for 3 days. You set up a streaming pipeline that reads data from the subscription, does a few Beam transformations, and then sinks to Cloud Storage. When the pipeline is launched, it is able to read from Pub/Sub, but cannot sink data to Cloud Storage due to the service account missing permissions to write to the bucket. When viewing the Job Metrics tab, what do you expect to see in the data freshness graph?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Initial start point at 3 days, with an upward sloping line.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Initial start point at 3 days, with a flat horizontal line.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Initial start point at 0 days, with an upward sloping line to 3 days and beyond.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Initial start point at 3 days, with a downward sloping line.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>You would like to set up an alerting policy to catch whether the processeddata isstill fresh in a streaming pipeline. Which metrics can be used to monitor whether the processeddata isstill fresh?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>job/system_lag</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>job/data_watermark_age</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>job/is_failed</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>job/per_stage_data_watermark_age</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Your batch job has failed, and when viewing the Diagnostic tab, you see the following insights: Out of memory: Kill process Shutting down JVM after consecutive periods of measured GC thrashing Which of the options below is the best one to undertake to resolve the issue?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Use a larger machine size</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Switch Beam code from Java to Python</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Increase Persistent Disk size</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Increase the number of machines used</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Select all that apply - the BigQuery Jobs tab shows jobs from:</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Query jobs</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Streaming Extracts</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Load jobs</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Streaming Inserts</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Your Dataflow batch job fails after running for close to 5 hours. Which two of the following troubleshooting steps would you take to understand the root cause of the failure?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Log the failing elements and check the output using Cloud Logging.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Monitor the Data Freshness and System Latency graphs to understand the job performance.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Investigate the wall time of the individual steps in the job.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Check the Dataflow worker logs for warnings or errors related to work item failures.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which two of the following statements are true for failures while building the pipeline?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>The failure can be caused by insufficient permissions granted to the controller service account.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>The failure can be caused by incorrect input/output specifications.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>The error message is visible in Dataflow.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>The failure is reproducible with the Direct Runner.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which one of the following is not a consideration for designing performant pipelines in Dataflow?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Filtering data early.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Logging</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Coders and decoders used in pipeline.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>SDK used for developing the pipeline.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>When should we avoid fusion in a Dataflow pipeline?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Never</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Always</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Only in specific scenarios, like if your pipeline involves massive fanouts.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Select options we can use to mitigate data skew in Dataflow pipelines?</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Use api like “withFanout” or “withHotKeyFanout”</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Use Dataflow shuffle for batch pipelines and Dataflow streaming option for streaming pipelines.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Add composite windows and triggers.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Add more worker machines.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>When draining a streaming pipeline, what should you expect to happen?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Both processing and ingestion stop immediately.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Ingestion stops immediately, windows are closed, and processing of in-flight elements will be allowed to complete.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>A snapshot is taken of the source, then ingestion is stopped. Windows are closed and processing of in-flight elements will be allowed to complete.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Any open windows will wait for new data so that aggregations are completed. Then the pipeline will be canceled.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Using anonymous subclasses in your ParDos is an anti-pattern because:</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Anonymous subclasses are bad for the performance of your pipeline.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Anonymous subclasses are harder to test than concrete subclasses.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>ParDos are required to contain a concrete subclass of a DoFn.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>You want to launch a streaming Dataflow job in europe-west4 and want to protect your pipeline from zonal stockouts. Which launch command will achieve these requirements?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>$ python3 -m apache_beam.examples.wordcount \ --input gs://dataflow-samples/shakespeare/kinglear.txt \ --output gs://$BUCKET/results/outputs --runner DataflowRunner \ --project $PROJECT --temp_location gs://$BUCKET/tmp/ \ --region europe-west4 --worker_zone europe-west4-b</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>$ python3 -m apache_beam.examples.wordcount \ --input gs://dataflow-samples/shakespeare/kinglear.txt \ --output gs://$BUCKET/results/outputs --runner DataflowRunner \ --project $PROJECT --temp_location gs://$BUCKET/tmp/ \ --region europe-west4</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>$ python3 -m apache_beam.examples.wordcount \ --input gs://dataflow-samples/shakespeare/kinglear.txt \ --output gs://$BUCKET/results/outputs --runner DataflowRunner \ --project $PROJECT --temp_location gs://$BUCKET/tmp/ \ </detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>How long is the retention for Dataflow Snapshots?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Three days</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Indefinitely</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Seven days</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Into which of the following categories are the Google-provided templates classified?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Streaming and utility only</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Batch, streaming, and utility</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Batch and streaming only</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Batch and utility only</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>How are Flex Templates packaged?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Jar/Pex</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Tar file</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>ProtoBuf binary</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Docker image</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which of the following is a challenge associated with classic templates?</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Increased latency while launching templates.</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Lack of support for runtime parameters.</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Lack of support for Dynamic DAG (Directed Acyclic Graph).</detail>
        </option>
      </options>
    </answer>
  </entry>

  <!--
  STRUCTURE DEFINITION:
  <entry>
    <question>XXX</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>XXX</detail>
        </option>
      </options>
    </answer>
  </entry>
  -->
</bank>