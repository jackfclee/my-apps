<?xml version='1.0' encoding='UTF-8'?>
<bank>
  <topic>PDE04 - Building Batch Data Pipelines on Google Cloud</topic>
  <entry>
    <question>Which of the following is the ideal use case for Extract and Load (EL)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Scheduled periodic loads of log files (e.g. once a day)</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>When the raw data needs to be quality-controlled, transformed, or enriched before being loaded into BigQuery</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>When the data loading has to happen continuously</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>When you want to integrate with continuous integration / continuous delivery (CI/CD) systems and perform unit testing on all components.</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Dataproc provides the ability for Spark programs to separate compute and storage by:</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Reading and writing data directly from/to Cloud Storage</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Setting individual zones for compute and storage</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Pre-copying data from Cloud Storage to persistent disk on cluster startup</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Mirroring data on both Cloud Storage and HDFS</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which of the following statements are true about Dataproc? (Select all 2 correct answers)</question>
    <answer>
      <options>
        <option>
          <valid>true</valid>
          <detail>Lets you run Spark and Hadoop clusters with minimal administration</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Helps you create job-specific clusters without HDFS</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Streamlined API for Spark and Hadoop programming</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Match each of the terms with what they do when setting up clusters in Dataproc:
| Term | Definition |
|---|---|
|__ 1. Zone	                  | A. Costs less but may not be available always |
|__ 2. Standard Cluster mode  | B. Determines the Google data center where compute nodes will be |
|__ 3. Preemptible            | C. Provides 1 primary and N workers |
</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>C, A, B</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C, B, A</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B, C, A</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>A, B, C</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Match each of the Dataflow terms with what they do in the life of a dataflow job:
| Term | Definition |
|---|---|
|__ 1. Transform    | A. Output endpoint for your pipeline |
|__ 2. PCollection  | B. A data processing operation or step in your pipeline |
|__ 3. Sink C.      | A set of data in your pipeline |
</question> 
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>B, A, C</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>A, C, B</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>B, C, A</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>C, B, A</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Which of the following statements are true? (Select all 2 correct responses)</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>Side-inputs in Dataflow are a way to export data from one pipeline to share with another pipeline</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Dataflow transforms support both batch and streaming pipelines</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>Map operations in a MapReduce can be performed by Combine transforms in Dataflow</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>Dataflow executes Apache Beam pipelines</detail>
        </option>
      </options>
    </answer>
  </entry>
  <entry>
    <question>Cloud Data Fusion is the ideal solution when you need</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>a data warehousing solution</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>to reuse spark pipelines</detail>
        </option>
        <option>
          <valid>false</valid>
          <detail>low-latency and high throughput processing of streaming data</detail>
        </option>
        <option>
          <valid>true</valid>
          <detail>to build visual pipelines</detail>
        </option>
      </options>
    </answer>
  </entry>
  <!--
  STRUCTURE DEFINITION:
  <entry>
    <question>XXX</question>
    <answer>
      <options>
        <option>
          <valid>false</valid>
          <detail>XXX</detail>
        </option>
      </options>
    </answer>
  </entry>
  -->
</bank>